<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lhlh1994.github.io</id>
    <title>Blog</title>
    <updated>2020-10-26T07:04:48.573Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lhlh1994.github.io"/>
    <link rel="self" href="https://lhlh1994.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://lhlh1994.github.io/images/avatar.png</logo>
    <icon>https://lhlh1994.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Blog</rights>
    <entry>
        <title type="html"><![CDATA[Spring Boot集成]]></title>
        <id>https://lhlh1994.github.io/post/spring-boot-ji-cheng/</id>
        <link href="https://lhlh1994.github.io/post/spring-boot-ji-cheng/">
        </link>
        <updated>2020-10-24T12:37:49.000Z</updated>
        <summary type="html"><![CDATA[<p>Spring Boot与其他框架的集成</p>
]]></summary>
        <content type="html"><![CDATA[<p>Spring Boot与其他框架的集成</p>
<!-- more -->
<h1 id="集成mybatis-plus">集成Mybatis-plus</h1>
<blockquote>
<p>基于Mybatis之上再次封装了一次，使得CURD变得更加简单<br>
官网：https://baomidou.com/</p>
</blockquote>
<p><strong>依赖</strong></p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.2.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>yml配置</strong></p>
<pre><code class="language-yml">spring:
  datasource: # 数据库配置
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/portrait?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;allowMultiQueries=true&amp;autoReconnect=true&amp;failOverReadOnly=false&amp;maxReconnects=10&amp;rewriteBatchedStatements=true
    username: root
    password: root
    hikari:
      connection-test-query: SELECT 1
      connection-timeout: 30000
      maximum-pool-size: 20
      max-lifetime: 60000
      minimum-idle: 5
      idle-timeout: 30000

# mybatis-plus相关配置
mybatis-plus:
  # xml扫描，多个目录用逗号或者分号分隔（告诉 Mapper 所对应的 XML 文件位置）
  mapper-locations: classpath:mapper/*.xml
  # 以下配置均有默认值,可以不设置
  global-config:
    db-config:
      #主键类型 AUTO:&quot;数据库ID自增&quot; INPUT:&quot;用户输入ID&quot;,ID_WORKER:&quot;全局唯一ID (数字类型唯一ID)&quot;, UUID:&quot;全局唯一ID UUID&quot;;
      id-type: auto
  configuration:
    # 是否开启自动驼峰命名规则映射:从数据库列名到Java属性驼峰命名的类似映射
    map-underscore-to-camel-case: true
    # 如果查询结果中包含空值的列，则 MyBatis 在映射的时候，不会映射这个字段
    call-setters-on-nulls: true
    # 这个配置会将执行的sql打印在控制台，在开发或测试的时候可以用。生产环境需要注释掉，否则debug日志将打印不出来
    # log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
</code></pre>
<p><strong>插件</strong></p>
<pre><code class="language-java">import com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class MybatisPlusConfig {
    /**
     * 分页插件
     */
    @Bean
    public PaginationInterceptor paginationInterceptor() {
        return new PaginationInterceptor();
    }
}
</code></pre>
<p><strong>注解</strong></p>
<ol>
<li>@TableName(&quot;user_info&quot;)   对应数据库中的表名</li>
<li>@TableId(type = IdType.AUTO)     指定id字段</li>
<li>@TableLogic(value = &quot;0&quot;, delval = &quot;1&quot;)   指定逻辑删除字段    0: 未删除 1: 删除</li>
</ol>
<blockquote>
<p>需要在Application类中添加注解 @MapperScan(basePackages = {&quot;com.wpt.dc.portrait.models.*.dao&quot;})</p>
</blockquote>
<p><strong>dao</strong></p>
<pre><code class="language-java">public interface UserInfoMapper extends BaseMapper&lt;UserInfo&gt; {
}
</code></pre>
<p><strong>service</strong></p>
<pre><code class="language-java">public interface UserInfoService extends IService&lt;UserInfo&gt; {
}
</code></pre>
<p><strong>serviceimpl</strong></p>
<pre><code class="language-java">@Service
public class GroupInfoServiceImpl extends ServiceImpl&lt;GroupInfoMapper, GroupInfo&gt; implements GroupInfoService {
}
</code></pre>
<h1 id="集成knife4j">集成Knife4j</h1>
<blockquote>
<p>基于Swagger2再次封装，拥有良好的UI界面，丰富了Swagger2的功能<br>
官网：https://doc.xiaominfo.com/guide/useful.html</p>
</blockquote>
<p><strong>依赖</strong></p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;
    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;2.0.4&lt;/version&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
            &lt;artifactId&gt;guava&lt;/artifactId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
    &lt;artifactId&gt;guava&lt;/artifactId&gt;
    &lt;version&gt;23.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>配置</strong></p>
<pre><code class="language-java">package com.wpt.dc.portrait.config;

import com.github.xiaoymin.knife4j.spring.annotations.EnableKnife4j;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Import;
import springfox.bean.validators.configuration.BeanValidatorPluginsConfiguration;
import springfox.documentation.builders.ApiInfoBuilder;
import springfox.documentation.builders.PathSelectors;
import springfox.documentation.builders.RequestHandlerSelectors;
import springfox.documentation.service.ApiInfo;
import springfox.documentation.spi.DocumentationType;
import springfox.documentation.spring.web.plugins.Docket;
import springfox.documentation.swagger2.annotations.EnableSwagger2;

@Configuration
@EnableSwagger2
@EnableKnife4j
@Import(BeanValidatorPluginsConfiguration.class)
public class SwaggerConfig {

    @Bean
    public Docket createRestApi() {
        return new Docket(DocumentationType.SWAGGER_2)
                // 指定构建api文档的详细信息的方法：apiInfo()
                .apiInfo(apiInfo())
                .select()
                // 指定要生成api接口的包路径，这里把controller作为包路径，生成controller中的所有接口
                .apis(RequestHandlerSelectors.basePackage(&quot;com.wpt.dc.portrait&quot;))
                .paths(PathSelectors.any())
                .build();
    }
    /**
     * 构建api文档的详细信息
     * @return
     */
    private ApiInfo apiInfo() {
        return new ApiInfoBuilder()
                // 设置页面标题
                .title(&quot;数据中台API文档&quot;)
                // 设置接口描述
                .description(&quot;数据中台API文档&quot;)
                // 设置版本
                .version(&quot;1.0&quot;)
                // 构建
                .build();
    }
}
</code></pre>
<p><strong>注解</strong></p>
<ol>
<li>@Api(&quot;控制层&quot;)</li>
<li>@ApiOperation(&quot;接口名称&quot;)</li>
<li>@Apimodel(&quot;实体类&quot;)</li>
<li>@ApiModelProperty(&quot;实体类属性&quot;)</li>
</ol>
<h1 id="集成forest">集成Forest</h1>
<blockquote>
<p>Forest 是一个开源的 Java HTTP 客户端框架，它能够将 HTTP 的所有请求信息（包括 URL、Header 以及 Body 等信息）绑定到您自定义的 Interface 方法上，能够通过调用本地接口方法的方式发送 HTTP 请求。<br>
官网：https://dt_flys.gitee.io/forest/#/</p>
</blockquote>
<p><strong>依赖</strong></p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.dtflys.forest&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-forest&lt;/artifactId&gt;
    &lt;version&gt;1.3.11&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>常用配置</strong></p>
<pre><code class="language-yml">forest:
  logEnabled: false # 打开或关闭日志，默认为true
  timeout: 30000  # 请求超时时间，单位为毫秒, 20s超时
  connect-timeout: 30000 # 连接超时时间，单位为毫秒, 20s超时
  # 自定义一些常量
  variables:
    esUrl: http://10.3.7.138:9200
    ssoUrl: http://login.weipaitang.com
    authUrl: http://authapit.weipaitang.com
</code></pre>
<p><strong>编写client</strong></p>
<pre><code class="language-java">@BaseRequest(baseURL = &quot;${esUrl}&quot;, headers = {
        &quot;Content-Type: application/json&quot;
})
public interface ESClient {
    @Request(
            url = &quot;/_sql&quot;,
            data = &quot;${json($data)}&quot;,
            type = &quot;POST&quot;
    )
    String queryBySql(@DataVariable(&quot;data&quot;) Map&lt;String, Object&gt; data, OnError onError);
}
</code></pre>
<p><strong>添加包扫描</strong></p>
<blockquote>
<p>需要在Application类上添加 <code>@ForestScan(basePackages = &quot;com.wpt.dc.portrait.client&quot;)</code>注解</p>
</blockquote>
<h1 id="集成redis">集成Redis</h1>
<h1 id="集成activemq">集成ActiveMQ</h1>
<h1 id="集成thymeleaf">集成Thymeleaf</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Boot学习笔记]]></title>
        <id>https://lhlh1994.github.io/post/spring-boot-xue-xi-bi-ji/</id>
        <link href="https://lhlh1994.github.io/post/spring-boot-xue-xi-bi-ji/">
        </link>
        <updated>2020-10-22T12:18:39.000Z</updated>
        <summary type="html"><![CDATA[<p>从零到一搭建Spring Boot企业级开发环境</p>
]]></summary>
        <content type="html"><![CDATA[<p>从零到一搭建Spring Boot企业级开发环境</p>
<!-- more -->
<h1 id="工程搭建">工程搭建</h1>
<p><strong>JDK选择</strong><br>
在IDEA 中配置 jdk 的方式很简单，打开<code>File-&gt;Project Structure</code>，如下图所：<br>
<img src="https://lhlh1994.github.io/post-images/1603369501129.png" alt="" loading="lazy"></p>
<ol>
<li>选择 SDKs</li>
<li>在 JDK home path 中选择本地 jdk 的安装目录</li>
<li>在 Name 中为 jdk 自定义名字</li>
</ol>
<p><strong>构建Spring Boot工程</strong><br>
通过<code>File-&gt;New-&gt;Project</code>可以快速构建Spring Boot工程</p>
<ul>
<li>Group：填企业域名，本课程使用com.itcodai</li>
<li>Artifact：填项目名称</li>
<li>Dependencies：可以添加我们项目中所需要的依赖信息，根据实际情况来添加</li>
</ul>
<p><strong>Maven配置</strong><br>
创建了 Spring Boot 项目之后，需要进行 maven 配置。打开<code>File-&gt;settings</code>，搜索 maven，配置一下本地的 maven 信息。如下：<br>
<img src="https://lhlh1994.github.io/post-images/1603369915322.png" alt="" loading="lazy"></p>
<ol>
<li>选择本机安装的Maven</li>
<li>选择公司的setting.xml文件</li>
<li>自定义Maven下载包的路径<br>
建议在setting.xml文件中添加，阿里云镜像</li>
</ol>
<pre><code class="language-xml">&lt;mirror&gt;
    &lt;id&gt;nexus-aliyun&lt;/id&gt;
    &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;
    &lt;name&gt;Nexus aliyun&lt;/name&gt;
    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;
&lt;/mirror&gt;
</code></pre>
<p><strong>编码设置</strong><br>
<code>File-&gt;settings</code><br>
<img src="https://lhlh1994.github.io/post-images/1603370132154.png" alt="" loading="lazy"></p>
<h1 id="返回json数据将null转为">返回json数据，将null转为&quot;&quot;</h1>
<p><strong>Jackson</strong></p>
<pre><code class="language-java">import com.fasterxml.jackson.core.JsonGenerator;
import com.fasterxml.jackson.databind.JsonSerializer;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializerProvider;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder;

import java.io.IOException;

@Configuration
public class JacksonConfig {
    @Bean
    @Primary
    @ConditionalOnMissingBean(ObjectMapper.class)
    public ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) {
        ObjectMapper objectMapper = builder.createXmlMapper(false).build();
        objectMapper.getSerializerProvider().setNullValueSerializer(new JsonSerializer&lt;Object&gt;() {
            @Override
            public void serialize(Object o, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
                jsonGenerator.writeString(&quot;&quot;);
            }
        });
        return objectMapper;
    }
}
</code></pre>
<p><strong>FastJson</strong></p>
<pre><code class="language-java">import com.alibaba.fastjson.serializer.SerializerFeature;
import com.alibaba.fastjson.support.config.FastJsonConfig;
import com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.MediaType;
import org.springframework.http.converter.HttpMessageConverter;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport;

import java.nio.charset.Charset;
import java.util.ArrayList;
import java.util.List;

@Configuration
public class fastJsonConfig extends WebMvcConfigurationSupport {

    /**
     * 使用阿里 FastJson 作为JSON MessageConverter
     * @param converters
     */
    @Override
    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {
        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();
        FastJsonConfig config = new FastJsonConfig();
        config.setSerializerFeatures(
                // 保留map空的字段
                SerializerFeature.WriteMapNullValue,
                // 将String类型的null转成&quot;&quot;
                SerializerFeature.WriteNullStringAsEmpty,
                // 将Number类型的null转成0
                SerializerFeature.WriteNullNumberAsZero,
                // 将List类型的null转成[]
                SerializerFeature.WriteNullListAsEmpty,
                // 将Boolean类型的null转成false
                SerializerFeature.WriteNullBooleanAsFalse,
                // 避免循环引用
                SerializerFeature.DisableCircularReferenceDetect);

        converter.setFastJsonConfig(config);
        converter.setDefaultCharset(Charset.forName(&quot;UTF-8&quot;));
        List&lt;MediaType&gt; mediaTypeList = new ArrayList&lt;&gt;();
        // 解决中文乱码问题，相当于在Controller上的@RequestMapping中加了个属性produces = &quot;application/json&quot;
        mediaTypeList.add(MediaType.APPLICATION_JSON);
        converter.setSupportedMediaTypes(mediaTypeList);
        converters.add(converter);
    }
}
</code></pre>
<h1 id="封装统一返回数据结构">封装统一返回数据结构</h1>
<pre><code class="language-java">import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;

@ApiModel(value = &quot;返回结果实体类&quot;)
public class Result&lt;T&gt; {
    @ApiModelProperty(value = &quot;状态信息&quot;, example = &quot;success&quot;)
    private String msg;
    @ApiModelProperty(value = &quot;状态码&quot;, example = &quot;0&quot;)
    private int code;
    @ApiModelProperty(&quot;数据内容&quot;)
    private T data;

    private Result(T data) {
        this.code = 0;
        this.msg = &quot;success&quot;;
        this.data = data;
    }

    private Result(CodeMsg cm) {
        if(cm == null){
            return;
        }
        this.code = cm.getCode();
        this.msg = cm.getMsg();
    }

    private Result(CodeMsg cm, String msg) {
        if(cm == null){
            return;
        }
        this.code = cm.getCode();
        this.msg = msg;
    }

    /**
     * 成功时候的调用
     * @return
     */
    public static &lt;T&gt; Result&lt;T&gt; success(T data){
        return new Result&lt;T&gt;(data);
    }
    /**
     * 成功，不需要传入参数
     * @return
     */
    @SuppressWarnings(&quot;unchecked&quot;)
    public static &lt;T&gt; Result&lt;T&gt; success(CodeMsg cm){
        return new Result&lt;T&gt;(cm);
    }
    /**
     * 失败时候的调用
     * @return
     */
    public static &lt;T&gt; Result&lt;T&gt; error(CodeMsg cm){
        return new Result&lt;T&gt;(cm);
    }
    /**
     * 失败时候的调用,扩展消息参数
     * @param cm
     * @param msg
     * @return
     */
    public static &lt;T&gt; Result&lt;T&gt; error(CodeMsg cm,String msg){
        return new Result&lt;T&gt;(cm, msg);
    }
    public T getData() {
        return data;
    }
    public String getMsg() {
        return msg;
    }
    public int getCode() {
        return code;
    }
}
</code></pre>
<h1 id="yml配置">yml配置</h1>
<p><strong>日志配置</strong></p>
<pre><code class="language-yml">logging:
  config: classpath:config/logback-spring.xml
  level:
    com.xxx.xxx: debug
</code></pre>
<p><strong>属性配置</strong></p>
<pre><code class="language-yml">server:
  port: 8001

# 配置微服务的地址  获取: 代码中通过@Value获取
url:
  # 订单微服务的地址
  orderUrl: http://localhost:8002
</code></pre>
<p><strong>多环境配置</strong></p>
<pre><code class="language-yml">spring:
  profiles:
    active: dev
</code></pre>
<p><strong>请求包体大小限制</strong></p>
<pre><code class="language-yml">servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 1024MB
</code></pre>
<h1 id="logbackxml配置">logback.xml配置</h1>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot;&gt;

    &lt;!--设置变量--&gt;
    &lt;springProperty scope=&quot;context&quot; name=&quot;LOG_HOME&quot; source=&quot;logging.path&quot;/&gt;
    &lt;springProperty scope=&quot;context&quot; name=&quot;LOG_LEVEL&quot; source=&quot;logging.pattern.level&quot;/&gt;

    &lt;!--日志输出格式--&gt;
    &lt;property name=&quot;LOG.PATTERN&quot; value=&quot;%d{yyyy-MM-dd HH:mm:ss.SSS} [%X{catRootId}] %-5level %logger{30} - %msg%n&quot;/&gt;

    &lt;!-- 日志文件大小--&gt;
    &lt;property name=&quot;LOG_MAX_SIZE&quot; value=&quot;1024MB&quot;/&gt;

    &lt;!-- 日志文件保留天数、最多允许占用的磁盘空间--&gt;
    &lt;property name=&quot;LOG_MAX_HISTORY&quot; value=&quot;10&quot;/&gt;
    &lt;property name=&quot;LOG_TOTAL_SIZE_CAP&quot; value=&quot;10GB&quot;/&gt;

    &lt;!-- DEBUG日志文件保留天数、最多允许占用的磁盘空间--&gt;
    &lt;property name=&quot;DEBUG_LOG_MAX_HISTORY&quot; value=&quot;1&quot;/&gt;
    &lt;property name=&quot;DEBUG_LOG_TOTAL_SIZE_CAP&quot; value=&quot;10GB&quot;/&gt;

    &lt;!--基于窗口大小的滚动策略 最多允许几个日志文件--&gt;
    &lt;property name=&quot;FIXED_WINDOWS_ROLLING_MIN_INDEX&quot; value=&quot;1&quot;/&gt;
    &lt;property name=&quot;FIXED_WINDOWS_ROLLING_MAX_INDEX&quot; value=&quot;3&quot;/&gt;

    &lt;!--应用日志，保留LOG_MAX_HISTORY天，最多占用LOG_TOTAL_SIZE_CAP空间--&gt;
    &lt;appender name=&quot;APPLICATION_FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;File&gt;${LOG_HOME}/application.log&lt;/File&gt;
        &lt;!-- 过滤器，只记录级别大于等于INFO的日志 --&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;TRACE&lt;/level&gt;
        &lt;/filter&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;
            &lt;FileNamePattern&gt;${LOG_HOME}/backup/application.%d{yyyy-MM-dd}.%i.log.zip&lt;/FileNamePattern&gt;
            &lt;maxFileSize&gt;${LOG_MAX_SIZE}&lt;/maxFileSize&gt;
            &lt;maxHistory&gt;${LOG_MAX_HISTORY}&lt;/maxHistory&gt;
            &lt;totalSizeCap&gt;${LOG_TOTAL_SIZE_CAP}&lt;/totalSizeCap&gt;
        &lt;/rollingPolicy&gt;
        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;
            &lt;pattern&gt;${LOG.PATTERN}&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!--控制台输出--&gt;
    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;TRACE&lt;/level&gt;
        &lt;/filter&gt;
        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;
            &lt;pattern&gt;${LOG.PATTERN}&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot;/&gt;
    &lt;logger name=&quot;org.mybatis.spring&quot; level=&quot;WARN&quot;/&gt;
    &lt;logger name=&quot;com.zaxxer.hikari&quot; level=&quot;INFO&quot;/&gt;
    &lt;logger name=&quot;springfox&quot; level=&quot;WARN&quot;/&gt;
    &lt;logger name=&quot;com.baomidou.mybatisplus.extension.plugins&quot; level=&quot;INFO&quot;/&gt;
    &lt;logger name=&quot;com.wpt.dcportrait.dao&quot; level=&quot;DEBUG&quot;/&gt;

    &lt;!--默认打开DEBUG日志--&gt;
    &lt;root level=&quot;${LOG_LEVEL}&quot;&gt;
        &lt;springProfile name=&quot;dev&quot;&gt;
            &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;
        &lt;/springProfile&gt;
        &lt;springProfile name=&quot;test&quot;&gt;
            &lt;appender-ref ref=&quot;APPLICATION_FILE&quot;/&gt;
        &lt;/springProfile&gt;
        &lt;springProfile name=&quot;prod&quot;&gt;
            &lt;appender-ref ref=&quot;APPLICATION_FILE&quot;/&gt;
        &lt;/springProfile&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<h1 id="全局异常处理">全局异常处理</h1>
<p><strong>定义业务异常类</strong></p>
<pre><code class="language-java">import com.wpt.dccommon.base.CodeMsg;
public class BusinessException extends RuntimeException {
    private CodeMsg codeMsg;
    public BusinessException() {
    }

    public BusinessException(CodeMsg codeMsg) {
        super(codeMsg.getMsg());
        this.codeMsg = codeMsg;
    }

    public CodeMsg getCodeMsg() {
        return codeMsg;
    }

    public void setCodeMsg(CodeMsg codeMsg) {
        this.codeMsg = codeMsg;
    }
}
</code></pre>
<p><strong>处理全局异常</strong></p>
<pre><code class="language-java">import com.dtflys.forest.exceptions.ForestNetworkException;
import com.wpt.dccommon.base.CodeMsg;
import com.wpt.dccommon.base.Result;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.http.HttpStatus;
import org.springframework.http.converter.HttpMessageNotReadableException;
import org.springframework.validation.BindException;
import org.springframework.validation.ObjectError;
import org.springframework.web.HttpRequestMethodNotSupportedException;
import org.springframework.web.bind.MethodArgumentNotValidException;
import org.springframework.web.bind.MissingServletRequestParameterException;
import org.springframework.web.bind.annotation.ControllerAdvice;
import org.springframework.web.bind.annotation.ExceptionHandler;
import org.springframework.web.bind.annotation.ResponseBody;
import org.springframework.web.bind.annotation.ResponseStatus;
import javax.validation.ConstraintViolation;
import javax.validation.ConstraintViolationException;
import java.util.List;
import java.util.stream.Collectors;

@ControllerAdvice
public class GlobalExceptionHandler {
    private static final Logger LOG = LoggerFactory.getLogger(GlobalExceptionHandler.class);

    /**
    * 参数校验
    */
    @ExceptionHandler(value = {BindException.class, MethodArgumentNotValidException.class})
    @ResponseBody
    public Result&lt;CodeMsg&gt; handleBindException(Exception ex){
        List&lt;String&gt; defaultMsg;
        if(ex instanceof BindException){
            defaultMsg = ((BindException) ex).getBindingResult().getAllErrors()
                    .stream()
                    .map(ObjectError::getDefaultMessage)
                    .collect(Collectors.toList());
        } else {
            defaultMsg = ((MethodArgumentNotValidException) ex).getBindingResult().getAllErrors()
                    .stream()
                    .map(ObjectError::getDefaultMessage)
                    .collect(Collectors.toList());
        }
        LOG.error(&quot;参数校验异常 {}&quot;, defaultMsg.get(0));
        return Result.error(CodeMsg.PARAMETER_VALID_FAILED, defaultMsg.get(0));
    }

    /**
    * 拦截必填参数未填异常
    * @author liuh
    * @date 2020/9/3 3:40 下午
    * @return com.wpt.dccommon.base.Result&lt;com.wpt.dccommon.base.CodeMsg&gt;
    */
    @ExceptionHandler(
            value = {MissingServletRequestParameterException.class, HttpMessageNotReadableException.class}
    )
    @ResponseBody
    public Result&lt;CodeMsg&gt; missingParameterException(Exception ex){
        String message = ex.getMessage();
        LOG.error(&quot;参数未找到：{}&quot;, message);
        return Result.error(CodeMsg.PARAMETER_ISNULL);
    }


    /**
    * 单个参数校验
    */
    @ExceptionHandler(value = ConstraintViolationException.class)
    @ResponseBody
    public Result&lt;CodeMsg&gt; handleBindGetException(ConstraintViolationException ex){
        List&lt;String&gt; defaultMsg = ex.getConstraintViolations()
                .stream()
                .map(ConstraintViolation::getMessage)
                .collect(Collectors.toList());
        LOG.error(&quot;参数校验异常：{}&quot;, defaultMsg.get(0));
        return Result.error(CodeMsg.PARAMETER_VALID_FAILED, defaultMsg.get(0));
    }

    /**
    * 拦截系统异常
    */
    @ExceptionHandler(Exception.class)
    @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)
    @ResponseBody
    public Result&lt;CodeMsg&gt; systemException (Exception e) {
        LOG.error(&quot;系统异常: &quot;, e);
        return Result.error(CodeMsg.SYSTEM_ERROR);
    }


    /**
    * 拦截业务
    */
    @ExceptionHandler(BusinessException.class)
    @ResponseBody
    public Result&lt;CodeMsg&gt; businessException (BusinessException ex) {
        LOG.error(&quot;业务异常: {}&quot;, ex.getCodeMsg().getMsg());
        CodeMsg codeMsg = ex.getCodeMsg();
        return Result.error(codeMsg);
    }

    /**
    * 拦截http调用异常
    */
    @ExceptionHandler(ForestNetworkException.class)
    @ResponseBody
    public Result&lt;CodeMsg&gt; forestNetworkException (ForestNetworkException ex) {
        LOG.error(&quot;http调用异常: &quot;, ex);
        return Result.error(CodeMsg.THIRD_HTTP_ERROR);
    }

    /**
    * 请求方式不正确异常
    */
    @ExceptionHandler(HttpRequestMethodNotSupportedException.class)
    @ResponseBody
    public Result&lt;CodeMsg&gt; httpRequestMethodNotSupportedException (HttpRequestMethodNotSupportedException ex) {
        LOG.error(&quot;请求方式不正确: &quot;, ex);
        return Result.error(CodeMsg.HTTP_METHOD_ERROR);
    }

    /**
    * 空指针异常
    */
    @ExceptionHandler(NullPointerException.class)
    @ResponseBody
    public Result&lt;CodeMsg&gt; nullPointerException (NullPointerException ex) {
        LOG.error(&quot;空指针异常: &quot;, ex);
        return Result.error(CodeMsg.NULL_POINTER_EXCEPTION);
    }
}
</code></pre>
<h1 id="拦截器">拦截器</h1>
<p><strong>自定义拦截器</strong></p>
<pre><code class="language-java">import com.fasterxml.jackson.databind.JsonNode;
import com.wpt.dc.portrait.exception.BusinessException;
import com.wpt.dc.portrait.utils.RequestWrapper;
import com.wpt.dccommon.base.CodeMsg;
import org.apache.http.entity.ContentType;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.web.bind.annotation.RequestMethod;
import org.springframework.web.servlet.ModelAndView;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;

public class AuthInterceptor implements HandlerInterceptor {
    private static final Logger LOG = LoggerFactory.getLogger(AuthInterceptor.class);

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws IOException {
        // 进入方案前的拦截，可以做一些登录、权限校验
        return true;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) {
        //log.info(&quot;执行完方法之后进执行(Controller方法调用之后)，但是此时还没进行视图渲染&quot;);
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) {
        //log.info(&quot;整个请求都处理完咯，DispatcherServlet也渲染了对应的视图咯，此时我可以做一些清理的工作了&quot;);
    }
}
</code></pre>
<p><strong>配置自定义拦截器</strong></p>
<pre><code class="language-java">import com.wpt.dc.portrait.interceptor.AuthInterceptor;
import com.wpt.dc.portrait.interceptor.PostDataInterceptor;
import com.wpt.dc.portrait.interceptor.SSOInterceptor;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;

@Configuration
public class InterceptorConfig implements WebMvcConfigurer {
    @Bean
    public SSOInterceptor ssoInterceptor() {
        return new SSOInterceptor();
    }

    @Bean
    public AuthInterceptor authInterceptor() {
        return new AuthInterceptor();
    }

    @Bean
    PostDataInterceptor postDataInterceptor() { return new PostDataInterceptor();}


    @Override

    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(postDataInterceptor());
        // 添加需要拦截的拦截器(可以配置多个)，已经需要拦截的路径和需要过滤的路径
        registry.addInterceptor(ssoInterceptor())
                .addPathPatterns(&quot;/**&quot;)
                .excludePathPatterns(&quot;/groupOpenApi/*&quot;, &quot;/notify/*&quot;, &quot;/source/importMetaData&quot;);
        registry.addInterceptor(authInterceptor())
                .addPathPatterns(&quot;/**&quot;)
                .excludePathPatterns(&quot;/info&quot;, &quot;/groupOpenApi/*&quot;, &quot;//info&quot;, &quot;/info/debug&quot;, &quot;/notify/*&quot;, &quot;/source/importMetaData&quot;);
    }
}
</code></pre>
<h1 id="过滤器">过滤器</h1>
<pre><code class="language-java">import com.wpt.dc.portrait.utils.RequestWrapper;
import javax.servlet.*;
import javax.servlet.annotation.WebFilter;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;

// 获取请求参数，要想获取post的请求参数需要用这种方式
@WebFilter(urlPatterns = &quot;*&quot;, filterName = &quot;channelFilter&quot;)
public class ChannelFilter implements Filter {
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        ServletRequest requestWrapper = null;
        if (request instanceof HttpServletRequest) {
            requestWrapper = new RequestWrapper((HttpServletRequest) request);
        }
        if (requestWrapper == null) {
            chain.doFilter(request, response);
        } else {
            chain.doFilter(requestWrapper, response);
        }
    }
</code></pre>
<h1 id="spring-boot-aop">Spring Boot AOP</h1>
<blockquote>
<p>AOP：Aspect Oriented Programming 的缩写，意为：面向切面编程。面向切面编程的目标就是分离关注点。什么是关注点呢？就是关注点，就是你要做的事情。假如你是一位公子哥，没啥人生目标，每天衣来伸手，饭来张口，整天只知道一件事：玩（这就是你的关注点，你只要做这一件事）！但是有个问题，你在玩之前，你还需要起床、穿衣服、穿鞋子、叠被子、做早饭等等等等，但是这些事情你不想关注，也不用关注，你只想想玩，那么怎么办呢？<br>
当然这些事情都是交给下人去做了，叫你起床、帮你穿衣服、帮你穿鞋、叠被子、做早饭等等，你只要关心怎么“玩”就好了。<br>
这就是AOP。AOP 的好处就是你只需要干你的正事，其它事情别人帮你干。或许某天你想裸奔，那只要把帮你穿衣服的下人下掉就好了；或许某天你想去买东西，那么只要再叫一个下人去帮你买就行了。</p>
</blockquote>
<p><strong>导入依赖</strong></p>
<pre><code class="language-xml">&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p><strong>自定义注解</strong></p>
<pre><code class="language-java">@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface LogHandler {
    String baseLog() default &quot;&quot;;
    String[] params();
}
</code></pre>
<p><strong>定义切面</strong></p>
<pre><code class="language-java">// 创建一个切面类
@Component
@Aspect
public class LogAspect {
    private static final Logger LOG = LoggerFactory.getLogger(LogAspect.class);

    // 定义切面需要拦截的东西，可以使用包名、自定义注解
    //@Pointcut(&quot;execution(* com.wpt.dc.portrait.controller..*.*(..))&quot;)
    @Pointcut(&quot;@annotation(LogHandler)&quot;)
    private void logHandleMethod() {
        
    }

    @Before(value = &quot;logHandleMethod()&quot;) // 指定切面
    public void doThrowing(JoinPoint joinPoint) {
        // do some things
    }

    @After(value = &quot;logHandleMethod()&quot;) // 指定切面
    public void doThrowing(JoinPoint joinPoint) {
        // do some things
    }

    @AfterReturning(value = &quot;logHandleMethod()&quot;) // 指定切面
    public void doThrowing(JoinPoint joinPoint) {
        // do some things
    }

    @AfterThrowing(value = &quot;logHandleMethod()&quot;) // 指定切面
    public void doThrowing(JoinPoint joinPoint) {
        // do some things
    }
}
</code></pre>
<p><strong>注解说明</strong></p>
<ol>
<li>@Pointcut：定义一个切面，即上面所描述的关注的某件事入口。</li>
<li>@Before：在做某件事之前做的事。</li>
<li>@After：在做某件事之后做的事。</li>
<li>@AfterReturning：在做某件事之后，对其返回值做增强处理。</li>
<li>@AfterThrowing：在做某件事抛出异常时，处理。</li>
</ol>
<p>如果拦截包名，<code>execution()</code> 为表达式主体<br>
第一个 <code>*</code> 号的位置：表示返回值类型，<code>*</code> 表示所有类型<br>
包名：表示需要拦截的包名，后面的两个句点表示当前包和当前包的所有子包，<code>com.wpt.dc.portrait.controller</code> 包、子包下所有类的方法<br>
第二个 <code>*</code> 号的位置：表示类名，<code>*</code> 表示所有类<br>
<code>*(..)</code> ：这个星号表示方法名，<code>*</code> 表示所有的方法，后面括弧里面表示方法的参数，两个句点表示任何参数</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[设计模式]]></title>
        <id>https://lhlh1994.github.io/post/she-ji-mo-shi/</id>
        <link href="https://lhlh1994.github.io/post/she-ji-mo-shi/">
        </link>
        <updated>2020-10-22T03:48:33.000Z</updated>
        <summary type="html"><![CDATA[<p>Java的23种设计模式，逐渐完善中</p>
]]></summary>
        <content type="html"><![CDATA[<p>Java的23种设计模式，逐渐完善中</p>
<!-- more -->
<h1 id="设计模式分类">设计模式分类</h1>
<figure data-type="image" tabindex="1"><img src="https://lhlh1994.github.io/post-images/1603352615759.png" alt="" loading="lazy"></figure>
<h1 id="代理模式">代理模式</h1>
<p><strong>接口</strong></p>
<pre><code class="language-java">public interface HelloService {
    void sayHello();
}
</code></pre>
<p><strong>接口实现</strong></p>
<pre><code class="language-java">public class HelloServiceImpl implements HelloService {
    @Override
    public void sayHello() {
        System.out.println(&quot;Hello World!&quot;);
    }
}
</code></pre>
<h2 id="静态代理">静态代理</h2>
<blockquote>
<p>静态代理代理类在编译期就生成，静态代理代码冗余大，一但需要修改接口，代理类和委托类都需要修改。</p>
</blockquote>
<pre><code class="language-java">public class HelloServiceStaticProxy implements HelloService {
    private HelloService helloService;
    public HelloServiceStaticProxy(HelloService helloService) {
        this.helloService = helloService;
    }
    @Override
    public void sayHello() {
        System.out.println(&quot;Before say hello...&quot;);
        helloService.sayHello();
        System.out.println(&quot;After say hello...&quot;);
    }

    // 测试
    public static void main(String[] args) {
        HelloServiceStaticProxy helloServiceStaticProxy = new HelloServiceStaticProxy(new HelloServiceImpl());
        helloServiceStaticProxy.sayHello();
    }
}
</code></pre>
<h2 id="动态代理">动态代理</h2>
<blockquote>
<p>Java中的动态代理代理类在JVM运行时动态生成，依靠反射来实现，委托类需要实现接口。<br>
Java动态代理主要涉及到两个类：java.lang.reflect.Proxy和java.lang.reflect.InvocationHandler。<br>
代理类需要实现InvocationHandler接口或者创建匿名内部类。</p>
</blockquote>
<pre><code class="language-java">public class HelloServiceDynamicProxy {
    private HelloService helloService;
    public HelloServiceDynamicProxy(HelloService helloService) {
        this.helloService = helloService;
    }
    public Object getProxyInstance() {
        return Proxy.newProxyInstance(helloService.getClass().getClassLoader(), helloService.getClass().getInterfaces(), new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                System.out.println(&quot;Before say hello...&quot;);
                Object ret = method.invoke(helloService, args);
                System.out.println(&quot;After say hello...&quot;);
                return ret;
            }
        });
    }

    public static void main(String[] args){
        HelloService helloService = new HelloServiceImpl();
        HelloService dynamicProxy = (HelloService) new HelloServiceDynamicProxy(helloService).getProxyInstance();
        dynamicProxy.sayHello();
    }
}
</code></pre>
<h1 id="单例模式">单例模式</h1>
<h2 id="饿汉式">饿汉式</h2>
<blockquote>
<p>饿汉式单例，随着项目的启动就已经创建类</p>
</blockquote>
<pre><code class="language-java">public class HungerSingle {

    private HungerSingle() {}
    private static HungerSingle single = new HungerSingle();
    public static HungerSingle getInstance() {
        return single;
    }

    public static void main(String[] args) {
        HungerSingle instance = HungerSingle.getInstance();
        System.out.println(instance);
    }
}
</code></pre>
<h2 id="懒汉式">懒汉式</h2>
<blockquote>
<p>懒汉式单例，用到时候才创建<br>
懒汉式存在多线程安全问题，因此每次调用的时候都需要加锁判断，效率较低</p>
</blockquote>
<pre><code class="language-java">public class LazySingle {
    private LazySingle() {
    }
    private static LazySingle single = null;
    public static synchronized LazySingle getInstance () {    //加锁同步安全
        if (single == null) {
            single = new LazySingle();
        }
        return single;
    }
    public static void main(String[] args) {
        LazySingle instance = LazySingle.getInstance();
        System.out.println(instance);
    }
}
</code></pre>
<h2 id="双重检查懒汉式">双重检查懒汉式</h2>
<blockquote>
<p>为了解决懒汉式效率问题，引入了双重检查机制，以提升效率</p>
</blockquote>
<pre><code class="language-java">public class DoubleCheckSingle {
    private DoubleCheckSingle() {
    }
    private static DoubleCheckSingle single = null;
    public static DoubleCheckSingle getInstance () {
        //1. 先检查实例是否存在，如果不存在才进入下面的同步块
        if (single == null) {
            synchronized (DoubleCheckSingle.class){
                //2. 可能会有多个线程进入1判断，需要再次检查实例是否存在，如果不存在才真正的创建实例
                if(single == null){
                    single = new DoubleCheckSingle();
                }
            }
        }
        return single;
    }

    public static void main(String[] args) {
        DoubleCheckSingle instance = DoubleCheckSingle.getInstance();
        System.out.println(instance);
    }
}
</code></pre>
<h2 id="静态内部类懒汉式">静态内部类懒汉式</h2>
<blockquote>
<p>除了双重检查机制之外还可以使用静态内部类的特点（只有在出现它的引用时才被加载），完成懒加载</p>
</blockquote>
<pre><code class="language-java">public class LazyMultithreadingSingle {
    private LazyMultithreadingSingle(){}
    public static LazyMultithreadingSingle getInstance(){
        return SingleHolder.instance;
    }
    private static class SingleHolder{
        public static LazyMultithreadingSingle instance = new LazyMultithreadingSingle();
    }

    public static void main(String[] args) {
        LazyMultithreadingSingle instance = LazyMultithreadingSingle.getInstance();
        System.out.println(instance);
    }
}
</code></pre>
<p>相关连接<br>
https://www.cnblogs.com/pony1223/p/7608955.html<br>
https://www.cnblogs.com/pony1223/p/7594803.html<br>
http://c.biancheng.net/design_pattern/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Git使用]]></title>
        <id>https://lhlh1994.github.io/post/git-shi-yong/</id>
        <link href="https://lhlh1994.github.io/post/git-shi-yong/">
        </link>
        <updated>2020-10-21T02:15:27.000Z</updated>
        <summary type="html"><![CDATA[<p>Git常用命令，以及使用方式</p>
]]></summary>
        <content type="html"><![CDATA[<p>Git常用命令，以及使用方式</p>
<!-- more -->
<h1 id="git-命令速查">git 命令速查</h1>
<p>git branch 查看本地所有分支<br>
git status 查看当前状态<br>
git commit 提交<br>
git branch -a 查看所有的分支<br>
git branch -r 查看远程所有分支<br>
git commit -am &quot;init&quot; 提交并且加注释<br>
git remote add origin git@192.168.1.119:ndshow<br>
git push origin master 将文件给推到服务器分支上<br>
git remote show origin 显示远程库origin里的资源<br>
git push origin master:hb-dev 将本地库与服务器上的库进行关联<br>
git checkout --track origin/dev 切换到远程dev分支<br>
git branch -D develop 删除本地库develop<br>
git checkout -b dev 建立一个新的本地分支dev<br>
git merge origin/dev 将分支dev与当前分支进行合并<br>
git checkout dev 切换到本地dev分支<br>
git remote show 查看远程库<br>
git add .<br>
git rm 文件名(包括路径) 从git中删除指定文件<br>
git clone git://github.com/schacon/grit.git 从服务器上将代码给拉下来<br>
git config --list 看所有用户<br>
git ls-files 看已经被提交的<br>
git rm [file name] 删除一个文件<br>
git commit -a 提交当前repos的所有的改变<br>
git add [file name] 添加一个文件到git index<br>
git commit -v 当你用－v参数的时候可以看commit的差异<br>
git commit -m &quot;This is the message describing the commit&quot; 添加commit信息<br>
git commit -a -a是代表add，把所有的change加到git index里然后再commit<br>
git commit -a -v 一般提交命令<br>
git log 看你commit的日志<br>
git diff 查看尚未暂存的更新<br>
git rm a.a 移除文件(从暂存区和工作区中删除)<br>
git rm --cached a.a 移除文件(只从暂存区中删除)<br>
git commit -m &quot;remove&quot; 移除文件(从Git中删除)<br>
git rm -f a.a 强行移除修改后文件(从暂存区和工作区中删除)<br>
git diff --cached 或 $ git diff --staged 查看尚未提交的更新<br>
git stash push 将文件给push到一个临时空间中<br>
git stash pop 将文件从临时空间pop下来<br>
git fetch 相当于是从远程获取最新版本到本地，不会自动merge</p>
<figure data-type="image" tabindex="1"><img src="https://lhlh1994.github.io/post-images/1603246945060.png" alt="Git 常用命令图表 " loading="lazy"></figure>
<h1 id="合并多次commit">合并多次commit</h1>
<h2 id="reset合并推荐">reset合并（推荐）</h2>
<pre><code class="language-sh">git status
git log
git reset -soft 2983d9b678d19602d0d574b137395ff82387fa1d(前一个提交)
git status
git add .
git commit -m &quot;feat: 本次版本内容&quot;
git push -f
</code></pre>
<h2 id="rebase合并">rebase合并</h2>
<pre><code class="language-sh"># 1. 查看最近提交记录
git log

# 2. 选择合并的起始点
git rebase -i 8d583c56

# 3. 将除第一行之外的 pick 设置为 s，然后 wq 保存并退出     s 的意思是这个 commit 会被合并到前一个 commit

# 4. 有冲突需要解决冲突，解决完之后需要执行如下命令
git add .
git rebase --continue

# 5. 进入 commit message 编辑页，修改commit message，然后输入 wq 保存并退出

# 6. 最后将代码push到远程分支
git push -f

# 过程中出现错误或者不想继续了，可以退出，并执行 git rebase --abort
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux基本命令]]></title>
        <id>https://lhlh1994.github.io/post/linux-ji-ben-ming-ling/</id>
        <link href="https://lhlh1994.github.io/post/linux-ji-ben-ming-ling/">
        </link>
        <updated>2020-10-21T02:03:32.000Z</updated>
        <summary type="html"><![CDATA[<p>Linux的常用命令</p>
]]></summary>
        <content type="html"><![CDATA[<p>Linux的常用命令</p>
<!-- more -->
<ol>
<li>
<p>进入文件夹</p>
<pre><code class="language-sh">cd /home    # 进入/home目录
cd ..       # 返回上一层目录
cd ../..		# 回到上上次层目录
cd -				# 回到上次的目录
cd ~				# 进入所登录用户的家目录
</code></pre>
</li>
<li>
<p>查看当前所在目录</p>
<pre><code class="language-shell">pwd
</code></pre>
</li>
<li>
<p>查看当前目录文件</p>
<pre><code class="language-sh">ls					# 查看当前目录下的非隐藏所有文件
ls -lh			# -l表示查看文件详情，-h表示显示单位
ls -a				# 查看当前目录下的所有文件（包括隐藏文件）
</code></pre>
</li>
<li>
<p>以树的方式显示文件和目录</p>
<pre><code class="language-sh">tree
lstree
</code></pre>
</li>
<li>
<p>创建文件夹</p>
<pre><code class="language-sh">mkdir demo
mkdir -p /data/logs/xxx		# 递归创建文件夹
</code></pre>
</li>
<li>
<p>创建文件</p>
<pre><code class="language-sh">touch 1.txt
</code></pre>
</li>
<li>
<p>拷贝文件或文件夹</p>
<pre><code class="language-sh">cp 1.txt xxx/1.txt			# 复制单个文件
cp -r xxx1 xxx2					# 递归复制文件夹（文件夹里面可以继续有文件夹）
</code></pre>
</li>
<li>
<p>移动或重命名文件或文件夹</p>
<pre><code class="language-sh">mv 1.txt 2.txt		  # 重命名
mv 1.txt xxx/1.txt  # 移动文件
mv xxx xxx1/xxx     # 移动目录
</code></pre>
</li>
<li>
<p>删除文件</p>
<pre><code class="language-sh">rm -rf 1.txt	# -r表示递归删除，-f表示强制删除
</code></pre>
</li>
<li>
<p>查看进程号</p>
<pre><code class="language-sh">ps -ef|grep 需要查的内容
# 命令参数：
# a  显示所有进程
# -a 显示同一终端下的所有程序
# -A 显示所有进程
# c  显示进程的真实名称
# -N 反向选择
# -e 等于“-A”
# e  显示环境变量
# f  显示程序间的关系
# -H 显示树状结构
# r  显示当前终端的进程
# T  显示当前终端的所有程序
# u  指定用户的所有进程
# -au 显示较详细的资讯
# -aux 显示所有包含其他使用者的行程 
# -C&lt;命令&gt; 列出指定命令的状况
# --lines&lt;行数&gt; 每页显示的行数
# --width&lt;字符数&gt; 每页显示的字符数
# --help 显示帮助信息
# --version 显示版本显示

# 如果要查看java进程可以使用下面的
jps 				
jps -l  	# 查看java进程详情，启动了那个main方法以及参数
jps -m 		# 查看java进程详情，java进程启动时所带的参数
</code></pre>
</li>
<li>
<p>查看端口号</p>
<pre><code class="language-sh">netstat -lanp|grep 需要查的内容
# -a (all)显示所有选项，默认不显示LISTEN相关
# -t (tcp)仅显示tcp相关选项
# -u (udp)仅显示udp相关选项
# -n 拒绝显示别名，能显示数字的全部转化成数字。
# -l 仅列出有在 Listen (监听) 的服務状态
# -p 显示建立相关链接的程序名
# -r 显示路由信息，路由表
# -e 显示扩展信息，例如uid等
# -s 按各个协议进行统计
# -c 每隔一个固定时间，执行该netstat命令。

# 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到
</code></pre>
</li>
<li>
<p>检测两台数据是否通讯正常</p>
<pre><code class="language-sh">ping 10.10.2.137
</code></pre>
</li>
<li>
<p>查看磁盘使用情况</p>
<pre><code class="language-sh">df -h
</code></pre>
</li>
<li>
<p>查看目录占用空间</p>
<pre><code class="language-sh">du -h
</code></pre>
</li>
<li>
<p>查找文件</p>
<pre><code class="language-sh">find / -name 1.txt		# 在 / 目录下，按名称查找1.txt的文件
find / -size -1000k		# 在 / 目录下，查找文件大小小于1000k的文件，如果是大于用+

which mysql 				  # 查看java指令所在的目录，通常用于检测程序是否卸载干净
</code></pre>
</li>
<li>
<p>编辑文件</p>
<pre><code class="language-sh">vi
vim   # vi的加强版，带有字体高亮，需要另外安装
# vi和vim作用是用来编辑文件，如果只是查看文件不要使用vi，vi会把文件全部加载到内存中，如果文件较大可能会把系统内存占满
</code></pre>
</li>
<li>
<p>查看文件内容</p>
<pre><code class="language-sh">cat 1.txt							# 查看文件全部内容，在查看大文件时 慎用
head -100 1.txt				# 查看文件的前100行，或者使用 head -n 100 1.txt
tail -100 1.txt				# 查看文件的倒数100行，或者使用 tail -n 100 1.txt
sed -n '5,10p' 1.txt	# 查看文件的5-10行内容
grep xxx 1.txt			  # 查看1.txt这个文件中，所有包含有xxx信息的行，可以使用正则表达式
</code></pre>
</li>
<li>
<p>授权文件给用户</p>
<pre><code class="language-sh">chown -R a1:a1 /data	# 将/data目录设置为a1用户的，-R表示该目录下的所有子文件夹以及子文件都同样生效
</code></pre>
</li>
<li>
<p>设置文件的权限</p>
<pre><code class="language-sh">chmod a+r 1.txt
# u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。
# + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。
# r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。
# -R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更)

# 或者使用数字授权
chmod 755 1.txt		# 第一位代表文件拥有者的权限，第二位代表文件拥有者所在组的权限，第三位代表其他用户的权限
# r=4，w=2，x=1
# 若要rwx属性则4+2+1=7；
# 若要rw-属性则4+2=6；
# 若要r-x属性则4+1=5。
</code></pre>
</li>
<li>
<p>查看java程序 gc情况</p>
<pre><code class="language-sh">jstat -gc 进程号
</code></pre>
</li>
<li>
<p>vi 命令</p>
<pre><code class="language-sh"># 以下所有命令均在esc状态下
:wq						# 保存并退出，最后加!表示强制
i							# 在光标所在的位置进入编辑状态，I表示在光标所在位置行的第一个字符进入编辑状态
o							# 在光标所在位置的下一行进入编辑状态
$							# 光标移动到该行的最后一个字符
^							# 光标移动到该行的第一个字符
/ aaa       	# 全文搜索包含aaa的内容，n下一个，N上一个
set number  	# 显示行号
set nonumber	# 关闭行号 
:100					# 直接跳到100行
G							# 直接跳到最后一行
gg						# 直接跳到第一行
dd						# 删除光标所在的当前行
d10d					# 删除光标所在行往下10行的全部内容
</code></pre>
</li>
<li>
<p>docker命令</p>
<pre><code class="language-sh">docker ps # 查看docker进程，可以查看服务的进程号，端口号
docker exec -it 进程号（服务名）bash # 进入docker服务
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql基础]]></title>
        <id>https://lhlh1994.github.io/post/mysql-ji-chu/</id>
        <link href="https://lhlh1994.github.io/post/mysql-ji-chu/">
        </link>
        <updated>2020-10-20T12:21:21.000Z</updated>
        <summary type="html"><![CDATA[<p>包含Mysql基本命令，函数，存储引擎介绍，事务，锁等知识</p>
]]></summary>
        <content type="html"><![CDATA[<p>包含Mysql基本命令，函数，存储引擎介绍，事务，锁等知识</p>
<!-- more -->
<h1 id="mysql基本操作">mysql基本操作</h1>
<ul>
<li>查看表结构    <code>desc 表名 或者 describe 表名</code></li>
<li>查看表详细结构语句    <code>show create table 表名</code></li>
<li>修改表名    <code>alter table 旧表名 rename 新表明</code></li>
<li>修改字段的数据类型    <code>alter table 表名 modify 字段名 数据类型</code></li>
<li>修改字段名    <code>alter table 表名 change 旧字段名 新字段名 新数据类型</code></li>
<li>添加字段    <code>alter table 表名 add 新字段名 数据类型 (约束条件) after 字段名</code></li>
<li>删除字段    <code>alter table 表名 drop 字段名</code></li>
<li>修改字段的排列位置    <code>alter table 表名 modify 字段1 数据类型 first|after 字段2</code></li>
<li>更改存储引擎    <code>alter table 表名 engine = 更改后的存储引擎名</code></li>
<li>删除外键约束    <code>alter table 表名 drop foreign key 外键约束名</code></li>
<li>创建索引    <code>create index 索引名 on 表名(字段名) alter table 表名 add key 索引名 (字段名)</code></li>
<li>删除索引    <code>drop index index_name on table_name</code></li>
<li>查看表死锁   <code>show processlist;</code><br>
<code>select trx_state, trx_started, trx_mysql_thread_id, trx_query from information_schema.innodb_trx;</code><br>
找到死锁进程，KILL掉</li>
<li>查看存储过程列表   <code>select name from mysql.proc where db = 'msx_online' and</code>type<code>= 'PROCEDURE';</code></li>
<li>查看数据库大小</li>
</ul>
<pre><code class="language-sql">use information_schema;

-- 所有数据大小
select table_schema as '数据库名',
       concat(round(sum(data_length/1024/1024/1024), 2), 'G') AS '数据大小',
       concat(round(sum(index_length/1024/1024/1024), 2), 'G') AS '索引大小',
       concat(round(sum((data_length+index_length) /1024/1024/1024), 2), 'G') AS '总大小'
from tables
group by table_schema
order by sum(data_length+index_length) desc;

-- 指定数据库大小
select table_name as '表名',
       concat(round(sum(data_length/1024/1024/1024), 2), 'G') AS '数据大小',
       concat(round(sum(index_length/1024/1024/1024), 2), 'G') AS '索引大小',
       concat(round(sum((data_length+index_length) /1024/1024/1024), 2), 'G') AS '总大小'
from tables
where table_schema= 'msx_report'
group by table_name
order by sum(data_length+index_length) desc;
</code></pre>
<ul>
<li>批量删除表<pre><code class="language-sql">SELECT CONCAT('DROP TABLE ', GROUP_CONCAT(table_name) ,';') as statment 
FROM information_schema.`TABLES` 
WHERE table_schema='ad' and table_name not in('ad_event_log','ad_request_event_log')
</code></pre>
</li>
<li>查看表的索引<pre><code class="language-sql">use information_schema;
select concat(round(sum(data_length/1024/1024),2),'MB') as data_length_MB,
concat(round(sum(index_length/1024/1024),2),'MB') as index_length_MB
from tables where
table_schema='DB'
and table_name = 'TABLE';
</code></pre>
</li>
<li>修正表信息(索引统计信息不正确时可以使用)    <code>analyze table t</code></li>
</ul>
<h1 id="mysqld的存储引擎">mysqld的存储引擎</h1>
<h2 id="1myisam">1.MyISAM</h2>
<blockquote>
<p>它不支持事务，也不支持外键，尤其是访问速度快，对事务完整性没有要求或者以SELECT、INSERT为主的应用基本都可以使用这个引擎来创建表。</p>
</blockquote>
<h2 id="2innodb">2.InnoDB</h2>
<blockquote>
<p>InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比MyISAM的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。</p>
</blockquote>
<h2 id="3memory">3.MEMORY</h2>
<blockquote>
<p>memory使用存在内存中的内容来创建表。每个MEMORY表实际对应一个磁盘文件，格式是.frm。MEMORY类型的表访问非常快，因为它到数据是放在内存中的，并且默认使用HASH索引，但是一旦服务器关闭，表中的数据就会丢失，但表还会继续存在。</p>
</blockquote>
<h2 id="4merge">4.MERGE</h2>
<blockquote>
<p>merge存储引擎是一组MyISAM表的组合，这些MyISAM表结构必须完全相同，MERGE表中并没有数据，对MERGE类型的表可以进行查询、更新、删除的操作，这些操作实际上是对内部的MyISAM表进行操作。对于对MERGE表进行的插入操作，是根据INSERT_METHOD子句定义的插入的表，可以有3个不同的值，first和last值使得插入操作被相应的作用在第一个或最后一个表上，不定义这个子句或者为NO，表示不能对这个MERGE表进行插入操作。可以对MERGE表进行drop操作，这个操作只是删除MERGE表的定义，对内部的表没有任何影响。MERGE在磁盘上保留2个以MERGE表名开头文件：.frm文件存储表的定义；.MRG文件包含组合表的信息，包括MERGE表由哪些表组成，插入数据时的依据。可以通过修改.MRG文件来修改MERGE表，但是修改后要通过flush table刷新。</p>
</blockquote>
<h2 id="5archive">5.Archive</h2>
<blockquote>
<p>如果只有insert和select操作,可以选择使用Archive引擎,Archive存储引擎支持高并发的插入操作,但是本身不支持事物。Archive存储引擎非常合适存储归档数据，如记录日志信息可以使用该引擎。</p>
</blockquote>
<h1 id="mysql的函数">mysql的函数</h1>
<pre><code class="language-sql">绝对值函数: abs(x)
返回圆周率的函数: pi()
平方根函数: sqrt(x)
取模函数: mod(x,y) x除以y之后的余数
返回不小于某个数的最小整数: ceil(x) 或者 ceiling(x)
返回不大于某个数的最大整数: floor(x)
随机数: rand() 或者 rand(x)
四舍五入: round(x) 或者 round(x,y) y表示结果保留y位小数,负数表示最后一位归零
去未: truncate(x,y) x:数值 y:保留几位小数,负数表示最后一位归零
符号函数: sing(x) 返回值有-1,0,1
Coalesce函数:功能：返回其参数中的第一个非空表达式，当你要在n个字段中选取某一个非空值
可以用它，比如下面语句
select Coalesce(null,null,1,2,null)union
select Coalesce(null,11,12,13,null)union
select Coalesce(111,112,113,114,null)
返回结果：
1
11
111
时间函数:
    DATE_ADD(date,INTERVAL 1 SESOND/MINITE/HOUR/DAY/MONTH/YEAR) -- 增加
    DATE_SUB(date,INTERVAL 1 SESOND/MINITE/HOUR/DAY/MONTH/YEAR) -- 减少
    DATE_FORMAT(date,'%Y-%m-%d %H:%i:%s') -- 格式化
GROUP_CONCAT(查询字段 separator ',') : 将一列字段的内容连接起来,默认连接符是&quot;,&quot;
GROUP BY 字段 WITH rollup 分组之后再进行一次聚合 null 表示聚合的字段
GROUP BY 字段 WITH cube 分组之后再进行一次聚合 null 表示聚合的字段
两者的区别是rullup对字段进行聚合;cube对字段值进行聚合
REPLACE(str,from_str,to_str) 在字符串 str 中所有出现的字符串 from_str 均被 to_str替换，然后返回这个字符串 
LTRIM(str) 将字符串前面的空格去掉，字符串中间的空格不会去掉  LTRIM('   2019 2') --&gt; 2019 2
</code></pre>
<h1 id="straight_join-关键字">STRAIGHT_JOIN 关键字</h1>
<blockquote>
<p>强制制定关联查询，让mysql按照用户想要的关联顺序去执行，不使用mysql的优化引擎。适用范围：适用于跟inner join等价的，当做left join使用时要小心。若右边的表没有数据，使用STRAIGHT_JOIN会查询不到数据。</p>
</blockquote>
<h1 id="and-or优先级">and &amp; or优先级</h1>
<blockquote>
<p>and 跟 or连用没有括号括起来的时候and的优先级比or高</p>
</blockquote>
<pre><code class="language-sql">SELECT
    *
from
    count
where
count = 1 and IN_STATION_ID = 2113442096093440
OR
count = 3 and IN_STATION_ID = 2113442096093440
</code></pre>
<h1 id="去重">去重</h1>
<ol>
<li>DISTINCT</li>
<li>GROUP BY</li>
</ol>
<h1 id="强制区分大小写排序">强制区分大小写排序</h1>
<pre><code class="language-sql">ORDER BY BINARY col_name
</code></pre>
<h1 id="日期操作">日期操作</h1>
<ol>
<li>TIMESTAMPDIFF(YEAR,start,end) 获得年份差值</li>
<li>TIMESTAMPDIFF(MONTH,start,end) 获得月份差值</li>
<li>TIMESTAMPDIFF(DAY,start,end) 获得天数差值</li>
<li>DATE_FORMAT(NOW(),%Y-%m-%d %H-%i-%s) 格式化日期</li>
</ol>
<h1 id="查询出重复数据中时间最新最早的一条">查询出重复数据中时间最新/最早的一条</h1>
<pre><code class="language-sql">-- 查询出重复数据中时间最新的一条
select
    a.TRADE_TIME,
    a.PAY_ID,a.BIZ_TRADE_NO
from stat_payinfo_3202 a
where not exists
(
    select 1
    from stat_payinfo_3202
    where BIZ_TRADE_NO=a.BIZ_TRADE_NO
    and TRADE_TIME&gt;a.TRADE_TIME
)

-- 查询出重复数据中时间最早的一条
SELECT C.BIZ_TRADE_NO,C.PAY_MONEY FROM order_info C,( -- 查询出当日首次扣费失败的订单及金额
    SELECT
     MIN(CREATE_TIME) CREATE_TIME,
     BIZ_TRADE_NO
    FROM
     order_info
    WHERE
     ORDER_STATUS = 104 -- 订单失败
     AND ORDER_TYPE = 203	-- 绑卡消费
     AND CITY_ID IN (3501,3404,4113)
     AND CREATE_TIME BETWEEN @DAY AND DATE_ADD(@DAY,INTERVAL 1 DAY)
    GROUP BY BIZ_TRADE_NO
   ) D WHERE C.CREATE_TIME = D.CREATE_TIME AND C.BIZ_TRADE_NO = D.BIZ_TRADE_NO
</code></pre>
<h1 id="数据类型转换">数据类型转换</h1>
<pre><code class="language-sql">1. Cast(value as type ),
2. convert(value,type),
其中类型可以为：
    CHAR[(N)] 字符型
    DATE 日期型
    DATETIME 日期和时间型
    DECIMAL float型
    SIGNED int
    TIME 时间型
</code></pre>
<h1 id="解决order-by-与union-不能一起用的方法">解决order by 与union 不能一起用的方法</h1>
<pre><code class="language-sql">(select IFNULL(OUT_TIME,IN_TIME),USER_ID,CITY_ID from fee_consumer_subway ORDER BY IFNULL(OUT_TIME,IN_TIME) desc limit 5)
UNION
(select IFNULL(OUT_TIME,IN_TIME),USER_ID,CITY_ID from fee_consumer_subway ORDER BY IFNULL(OUT_TIME,IN_TIME) asc limit 5)
</code></pre>
<h1 id="给结果集添加序号">给结果集添加序号</h1>
<pre><code class="language-sql">SELECT
 YEAR_WEEK,
 CONCAT('第',(@i:=@i+1),'周') as week
FROM
 dim_week_region A,(select @i:=0) B
WHERE
 WEEK_MONTH = DATE_FORMAT('${month}-01','%Y%m')
ORDER BY YEAR_WEEK ASC
</code></pre>
<h1 id="条件选择">条件选择</h1>
<pre><code class="language-sql">CASE
 WHEN ORDER_STATUS = 101 then '待支付'
 WHEN ORDER_STATUS = 102 then '订单支付处理中'
 WHEN ORDER_STATUS = 103 then '支付成功'
 WHEN ORDER_STATUS = 104 then '支付失败'
 WHEN ORDER_STATUS = 105 then '订单关闭'
 WHEN ORDER_STATUS = 106 then '取票中'
 WHEN ORDER_STATUS = 107 then '已出票'
 WHEN ORDER_STATUS = 108 then '退单中'
 WHEN ORDER_STATUS = 109 then '已退单'
ELSE ORDER_STATUS
END AS '订单状态'
</code></pre>
<h1 id="索引使用">索引使用</h1>
<pre><code class="language-sql">force index(index_name) -- 强制使用索引
ignore index(index_name) -- 禁止使用索引
</code></pre>
<h1 id="字符串截取">字符串截取</h1>
<pre><code class="language-sql">LEFT(str,length), RIGHT(str,length)
SELECT LEFT('www.yuanrengu.com',8) -- 从左边第一位开始截取特定长度 结果为:www.yuan
SELECT RIGHT('www.yuanrengu.com',6) -- 从左边第一位开始截取特定长度 结果为：gu.com

substring(str, pos)，即：substring(被截取字符串， 从第几位开始截取)
substring(str, pos, length)，即：substring(被截取字符串，从第几位开始截取，截取长度)

SUBSTRING_INDEX
SUBSTRING_INDEX('www.yuanrengu.com', '.', 2)  -- 截取第二个“.”之前的所有字符 结果为：www.yuanrengu
SELECT SUBSTRING_INDEX('www.yuanrengu.com', '.', -2) -- 截取倒数第二个“.”之后的所有字符 yuanrengu.com
SELECT SUBSTRING_INDEX('www.yuanrengu.com', 'sprite', 1) -- 如果关键字不存在，则返回整个字符串 结果为：www.yuanrengu.com
</code></pre>
<h1 id="字符串包含">字符串包含</h1>
<pre><code class="language-sql">方法一：
SELECT * FROM users WHERE emails like &quot;%b@email.com%&quot;;

方法二：
利用MySQL 字符串函数 find_in_set();
SELECT * FROM users WHERE find_in_set('aa@email.com', emails);
mysql有很多字符串函数 find_in_set(str1,str2)函数是返回str2中str1所在的位置索引，str2必须以&quot;,&quot;分割开。
注：当str2为NO1：“3,6,13,24,33,36”，NO2：“13,33,36,39”时，判断两个数据中str2字段是否包含‘3’，该函数可完美解决
mysql &gt; SELECT find_in_set('3','3,6,13,24,33,36') as test;
-&gt; 1
mysql &gt; SELECT find_in_set('3','13,33,36,39') as test;
-&gt; 0

方法三：
使用locate(substr,str)函数，如果包含，返回&gt;0的数，否则返回0
</code></pre>
<h1 id="锁机制">锁机制</h1>
<p><strong>事务</strong><br>
事务是一条或多条数据库操作语句的组合，具备ACID，4个特点。</p>
<ul>
<li>原子性：要不全部成功，要不全部撤销</li>
<li>隔离性：事务之间相互独立，互不干扰</li>
<li>一致性：数据库正确地改变状态后，数据库的一致性约束没有被破坏</li>
<li>持久性：事务的提交结果，将持久保存在数据库中</li>
</ul>
<p><strong>InnoDB引擎的锁机制</strong><br>
（之所以以InnoDB为主介绍锁，是因为InnoDB支持事务，支持行锁和表锁用的比较多，Myisam不支持事务，只支持表锁）<br>
共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。<br>
排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。<br>
意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。<br>
意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。</p>
<p><strong>悲观锁跟乐观锁</strong></p>
<ul>
<li>悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。</li>
<li>乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题。</li>
</ul>
<h1 id="myloadmydump导入导出">myload/mydump导入导出</h1>
<ol>
<li>安装</li>
</ol>
<pre><code class="language-sh">wget https://launchpadlibrarian.net/225370879/mydumper-0.9.1.tar.gz
yum install -y gcc gcc-c++ glib2-devel mysql-devel zlib-devel pcre-devel openssl-devel cmake
cd mydumper-0.9.1
cmake .   此处有.
make &amp;&amp; make install
验证安装是否正常：mydumper --help
</code></pre>
<ol start="2">
<li>导出</li>
</ol>
<pre><code class="language-sh">mysqldump -udbadmin -p -hrm-uf65xe9mz3b22cpeb.mysql.rds.aliyuncs.com bwt_tdtp b_trip b_order b_trip_confirm a_traffic_station a_traffic_line q_quickpass_trade b_refund --master-data=2  &gt;/opt/backup/tdtp.sql
</code></pre>
<ol start="3">
<li>导入</li>
</ol>
<pre><code class="language-sh">myloader -u root -p root -h 127.0.0.1 -P 3309 -o -d /opt/test/dump
</code></pre>
<h1 id="mysql导出csv格式文件">mysql导出csv格式文件</h1>
<pre><code class="language-sql">mysql -u username -h host -ppassword database -N -e &quot;SQL&quot; | sed -e 's/[\t]/,/g' &gt; /tmp/XXX.csv

-N: 不包含字段名
sed: s 替换 s/old/new/g 默认\t分隔
&gt;: 指定输出路径
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[dolphinscheduler部署]]></title>
        <id>https://lhlh1994.github.io/post/dolphinscheduler-bu-shu/</id>
        <link href="https://lhlh1994.github.io/post/dolphinscheduler-bu-shu/">
        </link>
        <updated>2020-10-20T08:12:24.000Z</updated>
        <summary type="html"><![CDATA[<p>ds1.2.0部署文档</p>
]]></summary>
        <content type="html"><![CDATA[<p>ds1.2.0部署文档</p>
<!-- more -->
<h1 id="dolphinscheduler部署文档集群版">dolphinscheduler部署文档（集群版）</h1>
<h2 id="集群规划">集群规划</h2>
<h3 id="ds集群生产配置">ds集群（生产配置）</h3>
<table>
<thead>
<tr>
<th>hostname</th>
<th>CPU</th>
<th>Memory</th>
<th>Disk size</th>
<th>Master</th>
<th>Worker</th>
<th>Logger</th>
<th>Alert</th>
<th>API</th>
<th>UI</th>
</tr>
</thead>
<tbody>
<tr>
<td>DS01</td>
<td>8C</td>
<td>16G</td>
<td>50G</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>DS02</td>
<td>8C</td>
<td>16G</td>
<td>50G</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DS03</td>
<td>4C</td>
<td>8G</td>
<td>50G</td>
<td></td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>若是部署了大数据框架，则机器性能需要进一步提升</strong></p>
<h3 id="zk集群">zk集群</h3>
<p>1C-2G-50G</p>
<h2 id="准备每台机器都要这样操作">准备（每台机器都要这样操作）</h2>
<h3 id="创建用户">创建用户</h3>
<pre><code># 创建用户需使用root登录，设置部署用户名，请自行修改，后面以dolphinscheduler为例
useradd dolphinscheduler;

# 设置用户密码，请自行修改，后面以dolphinscheduler123为例
echo &quot;dolphinscheduler&quot; | passwd --stdin dolphinscheduler

# 配置sudo免密
echo 'dolphinscheduler  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL' &gt;&gt; /etc/sudoers
</code></pre>
<h3 id="hosts映射">hosts映射</h3>
<pre><code>vi /etc/hosts

10.10.0.87  master
10.10.2.110  slave1
10.10.2.111  slave2
</code></pre>
<h3 id="配置免密登录">配置免密登录</h3>
<pre><code>su dolphinscheduler;

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys

# 分发
su dolphinscheduler;
for ip in ds2 ds3;     #请将此处ds2 ds3替换为自己要部署的机器的hostname
do
    ssh-copy-id  $ip   #该操作执行过程中需要手动输入dolphinscheduler用户的密码
done
# 当然 通过 sshpass -p xxx ssh-copy-id $ip 就可以省去输入密码了

在每台机器上使用ssh，需要输入yes，让机器记录下public-key，包括localhost
</code></pre>
<h2 id="下载">下载</h2>
<pre><code>后端: wget https://downloads.apache.org/incubator/dolphinscheduler/1.2.0/apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin.tar.gz
前端: wget https://downloads.apache.org/incubator/dolphinscheduler/1.2.0/apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin.tar.gz
</code></pre>
<h2 id="部署后端">部署后端</h2>
<h3 id="安装">安装</h3>
<pre><code>mkdir -p /opt/app/dolphinscheduler    # ds的安装目录
mkdir -p /opt/soft/dolphinscheduler    # ds的下载目录
cd /opt/soft/dolphinscheduler
tar -zxvf apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin.tar.gz -C /opt/app/dolphinscheduler
mv apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin  dolphinscheduler-backend

tree -L 1    # 查看目录结构
.
├── bin           # 基础服务启动脚本
├── conf          # 项目配置文件
├── DISCLAIMER-WIP# DISCLAIMER文件
├── install.sh    # 一键部署脚本
├── lib           # 项目依赖jar包，包括各个模块jar和第三方jar
├── LICENSE       # LICENSE文件
├── licenses      # 运行时license
├── NOTICE        # NOTICE文件
├── script        # 集群启动、停止和服务监控启停脚本
└── sql           # 项目依赖sql文件

# 授权解压目录
sudo chown -R dolphinscheduler:dolphinscheduler dolphinscheduler-backend
# 授权安装目录
sudo chown -R dolphinscheduler:dolphinscheduler /opt/app/dolphinscheduler
</code></pre>
<h3 id="jdk软连接">jdk软连接</h3>
<pre><code class="language-sh">echo $JAVA_HOME    # 没有软连接后面在启动脚本的时候会报错：nohup /bin/java不存在
sudo ln -s /usr/java/jdk1.8.0_111/bin/java /usr/bin/java
原先软连接关联的是openjdk的需要删掉
</code></pre>
<h3 id="数据库初始化">数据库初始化</h3>
<ul>
<li>创建数据库</li>
</ul>
<pre><code class="language-sql">mysql -uroot -p
-- 创建数据库
CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
-- 创建用户及授权（可能需要修改数据库密码等级）
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'dolphinscheduler'@'%' IDENTIFIED BY 'dolphinscheduler';
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'dolphinscheduler'@'localhost' IDENTIFIED BY 'dolphinscheduler';
flush privileges;
</code></pre>
<ul>
<li>修改配置</li>
</ul>
<pre><code>vi conf/application-dao.properties
# 需要注释掉postgresql的信息
# postgre
#spring.datasource.driver-class-name=org.postgresql.Driver
#spring.datasource.url=jdbc:postgresql://localhost:5432/dolphinscheduler
# mysql
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://master:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8     #需要修改ip，本机localhost即可
spring.datasource.username=dolphinscheduler
spring.datasource.password=dolphinscheduler
</code></pre>
<ul>
<li>执行脚本初始化数据表</li>
</ul>
<pre><code>sh script/create-dolphinscheduler.sh
</code></pre>
<p><strong>尖叫提示：执行脚本前需要下载mysql-java驱动程序包（需要选择对应mysql版本的驱动，不是bin），https://downloads.mysql.com/archives/c-j/</strong><br>
<strong>尖叫提示：如果执行上述脚本报 ”/bin/java: No such file or directory“ 错误，请在/etc/profile下配置 JAVA_HOME 及 PATH 变量</strong></p>
<h3 id="修改环境变量">修改环境变量</h3>
<pre><code class="language-sh">vi conf/env/.dolphinscheduler_env.sh    # 这是一个隐藏文件
# JAVA_HOME 和 PATH 是必须要配置的，其他没有用到的可以忽略或者注释掉
#export HADOOP_HOME=/opt/soft/hadoop
#export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop
#export SPARK_HOME1=/opt/soft/spark1
#export SPARK_HOME2=/opt/soft/spark2
#export PYTHON_HOME=/opt/soft/python
export JAVA_HOME=/usr/java/jdk1.8.0_111
#export HIVE_HOME=/opt/soft/hive
#export FLINK_HOME=/opt/soft/flink
export PATH=$HADOOP_HOME/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$PATH
</code></pre>
<h3 id="安装python的zookeeper工具kazoo每台都要安装">安装python的zookeeper工具kazoo（每台都要安装）</h3>
<pre><code>#安装pip
sudo yum -y install python-pip;  #ubuntu请使用 sudo apt-get install python-pip
sudo pip install kazoo;

# 注意：如果yum没找到python-pip，也可以通过下面方式安装
sudo curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python get-pip.py  # 如果是python3，使用sudo python3 get-pip.py
#然后
sudo pip install kazoo;
</code></pre>
<h3 id="修改一键部署脚本">修改一键部署脚本</h3>
<pre><code>vi install.sh
# for example postgresql or mysql ...
dbtype=&quot;mysql&quot;

# db config
# db address and port
dbhost=&quot;master:3306&quot;

# db name
dbname=&quot;dolphinscheduler&quot;

# db username
username=&quot;dolphinscheduler&quot;

# db passwprd
# Note: if there are special characters, please use the \ transfer character to transfer
passowrd=&quot;dolphinscheduler&quot;

# conf/config/install_config.conf config
# Note: the installation path is not the same as the current path (pwd)
# 将应用安装到哪个目录下
installPath=&quot;/opt/app/dolphinscheduler&quot;

# deployment user
# Note: the deployment user needs to have sudo privileges and permissions to operate hdfs. If hdfs is enabled, the root directory needs to be created by itself
# 使用哪个用户部署
deployUser=&quot;dolphinscheduler&quot;

# zk cluster,集群方式以逗号分隔
zkQuorum=&quot;master:2181,slave1:2181,slave2:2181&quot;

# install hosts
# Note: install the scheduled hostname list. If it is pseudo-distributed, just write a pseudo-distributed hostname
# 在哪些机器上部署
ips=&quot;master,slave1,slave2&quot;

# conf/config/run_config.conf config
# run master machine
# Note: list of hosts hostname for deploying master
masters=&quot;master,slave1&quot;

# run worker machine
# note: list of machine hostnames for deploying workers
workers=&quot;master,slave1,slave2&quot;

# run alert machine
# note: list of machine hostnames for deploying alert server
alertServer=&quot;master&quot;

# run api machine
# note: list of machine hostnames for deploying api server
apiServers=&quot;master&quot;

# 邮件服务
# alert config
# mail protocol
mailProtocol=&quot;SMTP&quot;

# mail server host
mailServerHost=&quot;hwSMTP.qiye.163.com&quot;

# mail server port
mailServerPort=&quot;994&quot;

# sender
mailSender=&quot;dtservice@bwton.com&quot;

# user
mailUser=&quot;dtservice@bwton.com&quot;

# sender password
mailPassword=&quot;BSngfWCyH7N8C5ZT&quot;

# TLS mail protocol support
starttlsEnable=&quot;false&quot;

sslTrust=&quot;hwSMTP.qiye.163.com&quot;

# SSL mail protocol support
# note: The SSL protocol is enabled by default.
# only one of TLS and SSL can be in the true state.
sslEnable=&quot;true&quot;

# download excel path
xlsFilePath=&quot;/tmp/xls&quot;

# 业务用到的比如sql等资源文件上传到哪里，可以设置：HDFS,S3,NONE，单机如果想使用本地文件系统，请配置为HDFS，因为HDFS支持本地文件系统；如果不需要资源上传功能请选择NONE。强调一点：使用本地文件系统不需要部署hadoop
resUploadStartupType=&quot;HDFS&quot;

# 这里以保存到本地文件系统为例
#注：但是如果你想上传到HDFS的话，NameNode启用了HA，则需要将core-site.xml和hdfs-site.xml放到conf目录下，本例即是放到/opt/dolphinscheduler/conf下面，并配置namenode cluster名称；如果NameNode不是HA,则修改为具体的ip或者主机名即可
defaultFS=&quot;hdfs://hadoopcluster/dolphinscheduler&quot;    #hdfs://{具体的ip/主机名}:8020

# 如果ResourceManager是HA，则配置为ResourceManager节点的主备ip或者hostname,比如&quot;192.168.xx.xx,192.168.xx.xx&quot;，否则如果是单ResourceManager或者根本没用到yarn,请配置yarnHaIps=&quot;&quot;即可，我这里没用到yarn，配置为&quot;&quot;
yarnHaIps=&quot;&quot;

# 如果是单ResourceManager，则配置为ResourceManager节点ip或主机名，否则保持默认值即可。我这里没用到yarn，保持默认
singleYarnIp=&quot;&quot;

# 由于hdfs支持本地文件系统，需要确保本地文件夹存在且有读写权限
hdfsPath=&quot;/data/dolphinscheduler&quot;
</code></pre>
<h3 id="执行一键部署脚本">执行一键部署脚本</h3>
<pre><code>su dolphinscheduler

sh install.sh
</code></pre>
<h3 id="查看进程是否启动">查看进程是否启动</h3>
<pre><code>jps

master
MasterServer         ----- master服务
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务
ApiApplicationServer ----- api服务
AlertServer          ----- alert服务

slave1
MasterServer         ----- master服务
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务

slave2
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务
</code></pre>
<h3 id="解压">解压</h3>
<pre><code>tar -zxvf apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin.tar.gz -C /opt/soft/dolphinscheduler;
mv apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin dolphinscheduler-ui
</code></pre>
<h2 id="部署前端">部署前端</h2>
<h3 id="部署">部署</h3>
<h4 id="自动化部署">自动化部署</h4>
<ul>
<li>执行自动化部署脚本</li>
</ul>
<pre><code>cd dolphinscheduler-ui;
sh ./install-dolphinscheduler-ui.sh;
执行后，会在运行中请键入前端端口，默认端口是8888，如果选择默认，键入回车，或者键入其他端口
然后会让键入跟前端ui交互的api-server的ip
接着是让键入跟前端ui交互的api-server的port
接着是操作系统选择
等待部署完成
</code></pre>
<ul>
<li>修改nginx配置</li>
</ul>
<pre><code>vi /etc/nginx/nginx.conf
# add param 在http方法体内添加即可
client_max_body_size 1024m;
systemctl restart nginx
</code></pre>
<h4 id="手动部署">手动部署</h4>
<ul>
<li>安装nginx，官网下载: http://nginx.org/en/download.html 或者 yum install nginx -y</li>
<li>修改nginx配置文件</li>
</ul>
<pre><code>vi /etc/nginx/nginx.conf
server {
  listen       8888;# 访问端口(自行修改)
  server_name  localhost;
  #charset koi8-r;
  #access_log  /var/log/nginx/host.access.log  main;
  location / {
      root   /opt/app/dolphinscheduler-ui/dist;      # 前端解压的dist目录地址(自行修改)
      index  index.html index.html;
  }
  location /dolphinscheduler {
      proxy_pass http://localhost:12345;    # api服务地址(自行修改)
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header x_real_ipP $remote_addr;
      proxy_set_header remote_addr $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_http_version 1.1;
      proxy_connect_timeout 4s;
      proxy_read_timeout 30s;
      proxy_send_timeout 12s;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection &quot;upgrade&quot;;
  }
  #error_page  404              /404.html;
  # redirect server error pages to the static page /50x.html
  #
  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
      root   /usr/share/nginx/html;
  }
}
</code></pre>
<h3 id="初始账号密码">初始账号密码</h3>
<p>地址：192.168.xx.xx:8888 用户名密码：admin/dolphinscheduler123</p>
<h2 id="指令">指令</h2>
<pre><code>启动：
    启动所有进程：sh bin/start-all.sh
    启动master-server：sh bin/dolphinscheduler-daemon.sh start master-server
    启动worker-server：sh bin/dolphinscheduler-daemon.sh start worker-server
    启动logger-server：sh bin/dolphinscheduler-daemon.sh start logger-server
    启动alert-server：sh bin/dolphinscheduler-daemon.sh start alert-server
    启动api-server：sh bin/dolphinscheduler-daemon.sh start api-server

停止：
    停止所有进程：sh bin/stop-all.sh
    停止master-server：sh bin/dolphinscheduler-daemon.sh stop master-server
    停止worker-server：sh bin/dolphinscheduler-daemon.sh stop worker-server
    停止logger-server：sh bin/dolphinscheduler-daemon.sh stop logger-server
    停止alert-server：sh bin/dolphinscheduler-daemon.sh stop alert-server
    停止api-server：sh bin/dolphinscheduler-daemon.sh stop api-server
</code></pre>
<h1 id="dolphinscheduler使用与测试文档">dolphinscheduler使用与测试文档</h1>
<h2 id="安全中心security">安全中心（Security）</h2>
<h3 id="队列管理queue-manage">队列管理（Queue manage）</h3>
<blockquote>
<p>队列是在执行 spark、mapreduce 等程序，需要用到“队列”参数时使用的（创建后不可删除）。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 队列管理 -&gt; 创建队列
------------------------------------------------------
名称：quene_test
队列值：quene_test
------------------------------------------------------
提交
</code></pre>
<h3 id="租户管理tenant-manage">租户管理（Tenant Manage）</h3>
<blockquote>
<p>租户对应的是 Linux 的用户，用于 worker 提交作业所使用的用户。<br>
如果 Linux 没有这个用户，worker 会在执行脚本的时候创建这个用户。<br>
租户编码：租户编码是 Linux 上的用户，唯一，不能重复。<br>
新建的租户会在 HDFS 上 $hdfsPath(&quot;/dolphinscheduler&quot;） 目录下创建租户目录，租户目录下为该租户上传的文件和 UDF 函数<br>
租户名称：租户编码的别名</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 租户管理 -&gt; 创建租户
------------------------------------------------------
租户编码：test
租户名称：test
队列值：default
------------------------------------------------------
提交

使用到HDFS需要为该用户在 HDFS 上创建用户目录
sudo -u hdfs hadoop fs -mkdir /user/developer
sudo -u hdfs hadoop fs -chown developer:developer /user/developer
</code></pre>
<h3 id="用户管理user-manage">用户管理（User Manage）</h3>
<blockquote>
<p>用户分为管理员用户和普通用户。<br>
授予权限包括：项目权限，资源权限，数据源权限，UDF函数权限。<br>
管理员可以对普通用户进行非其创建的项目、资源、数据源和UDF函数进行授权。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 用户管理 -&gt; 创建用户
------------------------------------------------------
用户名称：test
密码：test123
租户：test
队列：default
邮箱：liuhao@bwton.com
手机号：
-----------------------------------------------------+-
提交
</code></pre>
<p><strong>实际生产环境中，可将 项目、用户、租户 相关联，即为某个大的项目创建一个用户及对应的租户。若需要删除用户，则应首先将项目内的任务删除，然后删除项目，再删除用户及关联的租户，否则会出现任务无法运行，项目不可见等情况（1.2 版本）<br>
如果该 用户切换租户，则该 用户在当前租户下创建的所有资源 将 复制 到新的租户下（对于 HDFS 平台来说，则是将当前租户目录下该用户创建的所有资源复制到新租户的目录下，不复制被赋权的文件，且被赋权的文件仍有权限）。需要注意的是，此后进行文件删除操作时，旧租户下的对应的文件并不会被删除。</strong></p>
<h3 id="告警组管理warning-group-manage">告警组管理（Warning group manage）</h3>
<blockquote>
<p>告警组是在启动时设置的参数，在流程结束以后会将流程的状态和其他信息以邮件形式发送给告警组。</p>
</blockquote>
<h3 id="worker分组管理worker-group-manage">Worker分组管理（Worker group manage）</h3>
<blockquote>
<p>worker 分组，提供了一种让任务在指定的 worker 上运行的机制。<br>
管理员创建 worker 分组，在任务节点和运行参数中设置中可以指定该任务运行的 worker 分组。<br>
如果指定的分组被删除或者没有指定分组，则该任务会在任意一个 worker 上运行。worker 分组内多个 ip 地址（不能写别名），以英文逗号分隔。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; Worker分组管理 -&gt; 创建Worker分组
------------------------------------------------------
组名称：worker_group1
IP：10.10.0.87
------------------------------------------------------
提交
</code></pre>
<h3 id="令牌管理token-manage">令牌管理（Token manage）</h3>
<blockquote>
<p>由于后端接口有登录检查，令牌管理，提供了一种可以通过调用接口的方式对系统进行各种操作。</p>
</blockquote>
<h2 id="监控中心monitor">监控中心（Monitor）</h2>
<p>略</p>
<h2 id="数据源中心datasource">数据源中心（Datasource）</h2>
<pre><code>数据源中心 -&gt; 创建数据源 -&gt; MYSQL
------------------------------------------------------
数据源名称：10.10.0.87
描述：
IP主机名：10.10.0.87
端口：3306
用户名：root
密码：Bwton@2018
数据库名：test
jdbc连接参数：{&quot;useSSL&quot;:&quot;false&quot;,&quot;useUnicode&quot;:&quot;true&quot;,&quot;characterEncoding&quot;:&quot;UTF-8&quot;,&quot;allowMultiQueries&quot;:&quot;true&quot;}
------------------------------------------------------
测试链接 -&gt; 编辑
</code></pre>
<p>其他数据源：略</p>
<h2 id="资源中心resources">资源中心（Resources）</h2>
<blockquote>
<p>资源中心所有文件对应的 Mysql 表为：t_ds_resources<br>
UDF 对应的 Mysql 表为：t_ds_udfs<br>
资源中心的文件上传、删除操作使用的用户均为 install.sh 中指定的 $hdfsRootUser</p>
</blockquote>
<p>由于没有使用HDFS，略</p>
<h2 id="项目管理project">项目管理（Project）</h2>
<h3 id="创建项目">创建项目</h3>
<blockquote>
<p>项目名称 不可重复。即使为不同用户，创建项目时若 项目名称 已存在。会提示 “project Test already exists”。<br>
若要删除项目，需要确认项目中所有 工作流定义 都已下线并删除，才能进行删除操作。<br>
实际生产环境中，建议使用 管理员账户 创建项目，并对开发人员赋权。</p>
</blockquote>
<p>例：</p>
<pre><code>项目管理 -&gt; 创建项目
------------------------------------------------------
项目名称：测试项目
描述：
------------------------------------------------------
提交
</code></pre>
<h3 id="项目首页">项目首页</h3>
<pre><code>项目名称 -&gt; 项目首页
------------------------------------------------------
任务状态统计：是指在指定时间范围内，统计 任务实例 中的待运行、失败、运行中、完成、成功的个数
流程状态统计：是指在指定时间范围内，统计 工作流实例 中的待运行、失败、运行中、完成、成功的个数
流程定义统计：是统计当前用户有权限的项目的 工作流定义 总数
</code></pre>
<p><strong>工作流定义的工作流每运行一次，产生一个工作流实例，一个工作流实例包含一到多个任务实例。同一任务实例仅被统计一次，按最近时间状态进行统计。</strong></p>
<h3 id="工作流定义">工作流定义</h3>
<h4 id="创建工作流定义">创建工作流定义</h4>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
Step 1：拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
------------------------------------------------------
节点名称：task01
描述：This is a test task.
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
脚本：
    #!/bin/sh
    echo &quot;HELLO WORLD.&quot;
资源：
自定义参数：
------------------------------------------------------
    确认添加

Step 2：拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
------------------------------------------------------
节点名称：task02
描述：This is another test task.
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
脚本：
    #!/bin/sh
    echo &quot;HELLO DOLPHIN SCHEDULER.&quot;
资源：
自定义参数：
-&gt; 确认添加
------------------------------------------------------
Step 3：“选择线条连接”，连接任务1、2，tesk01、task02 会串行执行。
Step 4：保存
------------------------------------------------------
设置DAG图名称：Test_shell
选择租户：test
------------------------------------------------------
-&gt; 添加
</code></pre>
<p>更多任务类型详见：</p>
<h4 id="工作流定义操作功能">工作流定义操作功能</h4>
<p>工作流定义列表的操作功能如下：</p>
<ul>
<li>编辑： 只能编辑&quot;下线&quot;的工作流定义。工作流DAG编辑同创建工作流定义。</li>
<li>上线： 工作流状态为&quot;下线&quot;时，上线工作流，只有&quot;上线&quot;状态的工作流能运行，但不能编辑。</li>
<li>下线： 工作流状态为&quot;上线&quot;时，下线工作流，下线状态的工作流可以编辑，但不能运行。</li>
<li>运行： 只有上线的工作流能运行。运行操作步骤见 5.5.3.3 运行工作流</li>
<li>定时： 只有上线的工作流能设置定时，系统自动定时调度工作流运行。创建定时后的状态为&quot;下线&quot;，需在定时管理页面上线定时才生效。定时操作步骤见 5.5.3.4 工作流定时。</li>
<li>定时管理： 定时管理页面可编辑、上线/下线、删除定时。</li>
<li>删除： 删除工作流定义。</li>
<li>下载： 下载工作流定义到本地</li>
<li>树形图： 以树形结构展示任务节点的类型及任务状态</li>
</ul>
<h4 id="运行工作流">运行工作流</h4>
<p>工作流运行参数说明：</p>
<ul>
<li>失败策略：当某一个任务节点执行失败时，其他并行的任务节点需要执行的策略。”继续“表示：某一任务失败后，其他任务节点正常执行；”结束“表示：终止所有正在执行的任务，并终止整个流程。</li>
<li>通知策略：当流程结束，根据流程状态发送流程执行信息通知邮件，包含任何状态都不发，成功发，失败发，成功或失败都发。</li>
<li>流程优先级：流程运行的优先级，分五个等级：最高（HIGHEST），高(HIGH),中（MEDIUM）,低（LOW），最低（LOWEST）。当master线程数不足时，级别高的流程在执行队列中会优先执行，相同优先级的流程按照先进先出的顺序执行。</li>
<li>worker分组：该流程只能在指定的worker机器组里执行。默认是Default，可以在任一worker上执行。</li>
<li>通知组：选择通知策略||超时报警||发生容错时，会发送流程信息或邮件到通知组里的所有成员。</li>
<li>收件人：选择通知策略||超时报警||发生容错时，会发送流程信息或告警邮件到收件人列表。</li>
<li>抄送人：选择通知策略||超时报警||发生容错时，会抄送流程信息或告警邮件到抄送人列表。</li>
<li>补数：包括串行补数、并行补数2种模式。串行补数：指定时间范围内，从开始日期至结束日期依次执行补数，只生成一条流程实例；并行补数：指定时间范围内，多天同时进行补数，生成N条流程实例。</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 选择工作流名称“Test_shell” -&gt; 上线 -&gt; 运行（参数均为默认，不做修改）
</code></pre>
<h4 id="工作流定时">工作流定时</h4>
<pre><code>选择指定工作流，点击“定时”，选择起止时间、定时等选择定时执行时间。

点击&quot;创建&quot;按钮，创建定时成功，此时定时状态为&quot;下线&quot;，定时需上线才生效。
定时上线：点击&quot;定时管理&quot;按钮，进入定时管理页面，点击&quot;上线&quot;按钮，定时状态变为&quot;上线&quot;，如下图所示，工作流定时生效。
</code></pre>
<p><strong>下线 工作流定义 后，定时任务业务也会同时下线，工作流定义 上线后，需要重新手动上线定时任务</strong></p>
<h4 id="导入工作流">导入工作流</h4>
<pre><code>点击项目管理-&gt;工作流-&gt;工作流定义，进入工作流定义页面，点击&quot;导入工作流&quot;按钮，导入本地工作流文件，工作流定义列表显示导入的工作流，状态为下线。
</code></pre>
<h4 id="工作流实例">工作流实例</h4>
<p>工作流实例操作功能：</p>
<ul>
<li>编辑：可以对已经终止的流程进行编辑，编辑后保存的时候，可以选择是否 更新到工作流定义</li>
<li>重跑：可以对已经终止的流程进行重新执行</li>
<li>恢复失败：针对失败的流程，可以执行恢复失败操作，从失败的节点开始执行</li>
<li>停止：对正在运行的流程进行停止操作，后台会先 kill worker 进程，再执行 kill -9 操作</li>
<li>暂停：可以对正在运行的流程进行暂停操作，系统状态变为等待执行，会等待正在执行的任务结束，暂停下一个要执行的任务</li>
<li>恢复暂停：可以对暂停的流程恢复，直接从暂停的节点开始运行</li>
<li>删除：删除工作流实例及工作流实例下的任务实例</li>
<li>甘特图：Gantt图纵轴是某个工作流实例下的任务实例的拓扑排序，横轴是任务实例的运行时间</li>
</ul>
<pre><code>查看工作流实例：
项目管理 -&gt; 工作流 -&gt; 工作流实例 -&gt; 点击工作流名称 -&gt; 进入DAG查看页面，查看任务执行状态

查看任务日志：
进入DAG查看页面 -&gt; 双击任务节点 -&gt; 查看日志

查看任务历史记录：
进入DAG查看页面 -&gt; 双击任务节点 -&gt; 查看历史

查看运行参数：
进入工作流DAG页面 -&gt; 点击左上角图标，查看工作流实例的启动参数、全局参数和局部参数
</code></pre>
<h4 id="任务实例">任务实例</h4>
<pre><code>任务实例 -&gt; 点击工作流实例名称 -&gt; 可跳转到工作流实例DAG图查看任务状态
任务实例 -&gt; 查看日志
</code></pre>
<h3 id="任务节点类型和参数设置">任务节点类型和参数设置</h3>
<h4 id="shell节点">Shell节点</h4>
<p>运行说明：shell 节点，在 worker 执行的时候，会生成一个临时 shell 脚本，使用租户同名的linux 用户执行这个脚本。<br>
参数说明：</p>
<ul>
<li>节点名称：一个工作流定义中的节点名称是唯一的</li>
<li>运行标志：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关</li>
<li>描述信息：描述该节点的功能</li>
<li>任务优先级：级别高的任务在执行队列中会优先执行，相同优先级的任务按照先进先出的顺序执行</li>
<li>Worker分组：指定任务运行的机器列表</li>
<li>失败重试次数：任务失败重新提交的次数，支持下拉和手填</li>
<li>失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填</li>
<li>超时告警：当任务执行时间超过超时时长可以告警并且超时失败</li>
<li>脚本：用户开发的SHELL程序</li>
<li>资源：是指脚本中需要调用的资源文件列表</li>
<li>自定义参数：是SHELL局部的用户自定义参数，会替换脚本中以${变量}的内容</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
节点名称：Test_shell_01
运行标志：正常
描述：
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
超时告警：off
脚本：
    #!/bin/sh
    for i in {1..10};do echo $i;done
资源：
自定义参数：
-&gt; 确认添加

------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_shell
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="子流程节点">子流程节点</h4>
<p>运行说明：子流程节点，就是把外部的某个工作流定义当做一个任务节点去执行。<br>
参数说明：</p>
<ul>
<li>节点名称：一个工作流定义中的节点名称是唯一的</li>
<li>运行标志：标识这个节点是否能正常调度</li>
<li>描述信息：描述该节点的功能</li>
<li>超时告警：勾选超时告警、超时失败，当任务超过&quot;超时时长&quot;后，会发送告警邮件并且任务执行失败</li>
<li>子节点：是选择子流程的工作流定义，右上角进入该子节点可以跳转到所选子流程的工作流定义</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

Task 1：拖拽 SHELL 节点到画布，新增一个 Shell 任务
节点名称：Test_subprocess_01
... ...
脚本：
    #!/bin/sh
    for i in {1..10};do echo $i;done
-&gt; 确认添加
Task 2：拖拽 SUB_PROCESS 节点到画布，新增一个 SUB_PROCESS 任务
节点名称：Test_subprocess_02
... ...
子节点：Test_shell
-&gt; 确认添加

------------------------------------------------------

串联任务节点 Task1 和 Task2
------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_subprocess
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="存储过程节点">存储过程节点</h4>
<p>运行说明：根据选择的数据源，执行存储过程。<br>
参数说明：</p>
<ul>
<li>数据源：存储过程的数据源类型支持 MySQL、POSTGRESQL、CLICKHOUSE、ORACLE、SQLSERVER 等，选择对应的数据源</li>
<li>方法：是存储过程的方法名称</li>
<li>自定义参数：存储过程的自定义参数类型支持 IN、OUT 两种，数据类型支持 VARCHAR、INTEGER、LONG、FLOAT、DOUBLE、DATE、TIME、TIMESTAMP、BOOLEAN 九种数据类型</li>
</ul>
<h4 id="sql节点">SQL节点</h4>
<p>参数说明：</p>
<ul>
<li>数据源：选择对应的数据源</li>
<li>sql类型：支持查询和非查询两种，查询是 select 类型的查询，是有结果集返回的，可以指定邮件通知为 表格、附件 或 表格与附件 三种模板。非查询是没有结果集返回的，是针对 update、delete、insert 三种类型的操作</li>
<li>主题、收件人、抄送人：邮件相关配置</li>
<li>sql参数：输入参数格式为 key1=value1;key2=value2…</li>
<li>sql语句：SQL语句</li>
<li>UDF函数：对于HIVE类型的数据源，可以引用资源中心中创建的UDF函数,其他类型的数据源暂不支持UDF函数</li>
<li>自定义参数：SQL任务类型，而存储过程是自定义参数顺序的给方法设置值自定义参数类型和数据类型同存储过程任务类型一样。区别在于SQL任务类型自定义参数会替换sql语句中 ${变量}</li>
<li>前置sql：执行 “sql语句” 前的操作</li>
<li>后置sql：执行 “sql语句” 后的操作</li>
</ul>
<p>例，以mysql为例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

Task 1：拖拽 SQL 节点到画布，新增一个 SQL 任务
节点名称：Test_sql_mysql_01
... ...
数据源：MYSQL   10.10.0.87
sql类型：查询   表格：√ 附件：√
主题：Test MySQL
收件人：liuhao@bwton.com
sql语句：
    select * from test_table where score=${i};
自定义参数：
    i -&gt; IN -&gt; INTEGER -&gt; 97
前置sql:
    INSERT INTO test_table values(null, 'Dog',97)
后置sql：
-&gt; 确认添加
Task 2：拖拽 SQL 节点到画布，新增一个 SQL 任务
节点名称：Test_sql_mysql_02
... ...
数据源：MYSQL   10.10.0.87
sql类型：非查询
sql语句：
    create table test_table2 as select * from test_table;
自定义参数：
前置sql:
后置sql：
-&gt; 确认添加

------------------------------------------------------

串联任务节点 Test_sql_mysql_01、Test_sql_mysql_02
------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_sql_mysql
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="依赖dependent节点">依赖(DEPENDENT)节点</h4>
<p>运行说明：依赖节点，就是依赖检查节点。比如A流程依赖昨天的B流程执行成功，依赖节点会去检查B流程在昨天是否有执行成功的实例。</p>
<h4 id="其他节点略">其他节点，略</h4>
<h2 id="参数">参数</h2>
<h3 id="系统参数">系统参数</h3>
<table>
<thead>
<tr>
<th>变量</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>${system.biz.date}</td>
<td>日常调度实例定时的定时时间前一天，格式为 yyyyMMdd，补数据时，该日期 +1</td>
</tr>
<tr>
<td>${system.biz.curdate}</td>
<td>日常调度实例定时的定时时间，格式为 yyyyMMdd，补数据时，该日期 +1</td>
</tr>
<tr>
<td>${system.datetime}</td>
<td>日常调度实例定时的定时时间，格式为 yyyyMMddHHmmss，补数据时，该日期 +1</td>
</tr>
</tbody>
</table>
<h3 id="自定义参数">自定义参数</h3>
<ul>
<li>支持代码中自定义变量名，声明方式：${变量名}。可以是引用 &quot;系统参数&quot; 或指定 &quot;常量&quot;。</li>
<li>我们定义这种基准变量为 [...] 格式的，[yyyyMMddHHmmss] 是可以任意分解组合的，比如：$[yyyyMMdd], $[HHmmss], $[yyyy-MM-dd] 等</li>
<li>也可以使用以下格式：</li>
</ul>
<pre><code>* 后 N 年：$[add_months(yyyyMMdd,12*N)]
* 前 N 年：$[add_months(yyyyMMdd,-12*N)]
* 后 N 月：$[add_months(yyyyMMdd,N)]
* 前 N 月：$[add_months(yyyyMMdd,-N)]
* 后 N 周：$[yyyyMMdd+7*N]
* 前 N 周：$[yyyyMMdd-7*N]
* 后 N 天：$[yyyyMMdd+N]
* 前 N 天：$[yyyyMMdd-N]
* 后 N 小时：$[HHmmss+N/24]
* 前 N 小时：$[HHmmss-N/24]
* 后 N 分钟：$[HHmmss+N/24/60]
* 前 N 分钟：$[HHmmss-N/24/60]
</code></pre>
<h2 id="官方使用文档">官方使用文档</h2>
<p><a href="https://dolphinscheduler.apache.org/zh-cn/docs/1.2.0/user_doc/quick-start.html">https://dolphinscheduler.apache.org/zh-cn/docs/1.2.0/user_doc/quick-start.html</a></p>
<h2 id="出现的问题">出现的问题</h2>
<h3 id="创建租户">创建租户</h3>
<ul>
<li>租户对应的是Linux的用户，用于worker提交作业所使用的用户。如果linux没有这个用户，worker会在执行脚本的时候创建这个用户。</li>
<li>租户编码：租户编码是Linux上的用户，唯一，不能重复</li>
<li>出现创建不了租户原因
<ol>
<li>ds的启动用户没有创建用户的权限</li>
<li>linux系统禁用了sudo，进入/etc/sudoers 将 Default requiretty注释掉</li>
</ol>
</li>
</ul>
<h3 id="创建用户-2">创建用户</h3>
<ul>
<li>权限划分，目的是为了更好的管理项目，资源，UDF，数据源等信息。</li>
<li>创建用户需要指定租户（要想admin用户有执行权限，需要给admin用户赋予租户）</li>
</ul>
<h3 id="调度未执行">调度未执行</h3>
<blockquote>
<p>定时任务上线成功，调度未执行，查看master没有打印错误日志</p>
</blockquote>
<ul>
<li>原因可能是quartz在启动时就报错了，导致quartz初始化没有成功。</li>
<li>修改master_logback.xml</li>
</ul>
<pre><code>&lt;root level=&quot;INFO&quot;&gt;
    &lt;appender-ref ref=&quot;MASTERLOGFILE&quot;/&gt;
    &lt;!-- 增加日志到控制台--&gt;
    &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;
&lt;/root&gt;
</code></pre>
<ul>
<li>查看master.out文件</li>
</ul>
]]></content>
    </entry>
</feed>