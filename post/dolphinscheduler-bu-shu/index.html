<html>
<head>
    <meta charset="utf-8"/>
<meta name="description" content=""/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>

<title>dolphinscheduler部署 | Blog</title>

<link rel="shortcut icon" href="https://lhlh1994.github.io/favicon.ico?v=1603181791462">

<link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://lhlh1994.github.io/styles/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/css/bootstrap.min.css">

<script src="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.15.10/languages/dockerfile.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.15.10/languages/dart.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/moment@2.27.0/moment.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.0/dist/js/bootstrap.min.js"></script>
<!-- DEMO JS -->
<!--<script src="media/scripts/index.js"></script>-->



    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.css">
</head>
<body>
<div class="main gt-bg-theme-color-first">
    <nav class="navbar navbar-expand-lg">
    <div class="navbar-brand">
        <img class="user-avatar" src="/images/avatar.png" alt="头像">
        <div class="site-name gt-c-content-color-first">
            Blog
        </div>
    </div>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <i class="fas fa-bars gt-c-content-color-first" style="font-size: 18px"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <div class="navbar-nav mr-auto" style="text-align: center">
            
                <div class="nav-item">
                    
                        <a href="/" class="menu gt-a-link">
                            首页
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/archives" class="menu gt-a-link">
                            归档
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/tags" class="menu gt-a-link">
                            标签
                        </a>
                    
                </div>
            
                <div class="nav-item">
                    
                        <a href="/post/about" class="menu gt-a-link">
                            关于
                        </a>
                    
                </div>
            
        </div>
        <div style="text-align: center">
            <form id="gridea-search-form" style="position: relative" data-update="1603181791462" action="/search/index.html">
                <input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="搜索文章" />
                <i class="fas fa-search gt-c-content-color-first" style="position: absolute; top: 9px; left: 10px;"></i>
            </form>
        </div>
    </div>
</nav>

    <div class="post-container">
        <div class="post-detail gt-bg-theme-color-second">
            <article class="gt-post-content">
                <h2 class="post-title">
                    dolphinscheduler部署
                </h2>
                <div class="post-info">
                    <time class="post-time gt-c-content-color-first">
                        · 2020-10-20 ·
                    </time>
                    
                        <a href="https://lhlh1994.github.io/tag/Bc6DxoHCx/" class="post-tags">
                            # bigdata
                        </a>
                    
                </div>
                <div class="post-content">
                    <h1 id="dolphinscheduler部署文档集群版">dolphinscheduler部署文档（集群版）</h1>
<h2 id="集群规划">集群规划</h2>
<h3 id="ds集群生产配置">ds集群（生产配置）</h3>
<table>
<thead>
<tr>
<th>hostname</th>
<th>CPU</th>
<th>Memory</th>
<th>Disk size</th>
<th>Master</th>
<th>Worker</th>
<th>Logger</th>
<th>Alert</th>
<th>API</th>
<th>UI</th>
</tr>
</thead>
<tbody>
<tr>
<td>DS01</td>
<td>8C</td>
<td>16G</td>
<td>50G</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>DS02</td>
<td>8C</td>
<td>16G</td>
<td>50G</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DS03</td>
<td>4C</td>
<td>8G</td>
<td>50G</td>
<td></td>
<td>√</td>
<td>√</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>若是部署了大数据框架，则机器性能需要进一步提升</strong></p>
<h3 id="zk集群">zk集群</h3>
<p>1C-2G-50G</p>
<h2 id="准备每台机器都要这样操作">准备（每台机器都要这样操作）</h2>
<h3 id="创建用户">创建用户</h3>
<pre><code># 创建用户需使用root登录，设置部署用户名，请自行修改，后面以dolphinscheduler为例
useradd dolphinscheduler;

# 设置用户密码，请自行修改，后面以dolphinscheduler123为例
echo &quot;dolphinscheduler&quot; | passwd --stdin dolphinscheduler

# 配置sudo免密
echo 'dolphinscheduler  ALL=(ALL)  NOPASSWD: NOPASSWD: ALL' &gt;&gt; /etc/sudoers
</code></pre>
<h3 id="hosts映射">hosts映射</h3>
<pre><code>vi /etc/hosts

10.10.0.87  master
10.10.2.110  slave1
10.10.2.111  slave2
</code></pre>
<h3 id="配置免密登录">配置免密登录</h3>
<pre><code>su dolphinscheduler;

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys

# 分发
su dolphinscheduler;
for ip in ds2 ds3;     #请将此处ds2 ds3替换为自己要部署的机器的hostname
do
    ssh-copy-id  $ip   #该操作执行过程中需要手动输入dolphinscheduler用户的密码
done
# 当然 通过 sshpass -p xxx ssh-copy-id $ip 就可以省去输入密码了

在每台机器上使用ssh，需要输入yes，让机器记录下public-key，包括localhost
</code></pre>
<h2 id="下载">下载</h2>
<pre><code>后端: wget https://downloads.apache.org/incubator/dolphinscheduler/1.2.0/apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin.tar.gz
前端: wget https://downloads.apache.org/incubator/dolphinscheduler/1.2.0/apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin.tar.gz
</code></pre>
<h2 id="部署后端">部署后端</h2>
<h3 id="安装">安装</h3>
<pre><code>mkdir -p /opt/app/dolphinscheduler    # ds的安装目录
mkdir -p /opt/soft/dolphinscheduler    # ds的下载目录
cd /opt/soft/dolphinscheduler
tar -zxvf apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin.tar.gz -C /opt/app/dolphinscheduler
mv apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-backend-bin  dolphinscheduler-backend

tree -L 1    # 查看目录结构
.
├── bin           # 基础服务启动脚本
├── conf          # 项目配置文件
├── DISCLAIMER-WIP# DISCLAIMER文件
├── install.sh    # 一键部署脚本
├── lib           # 项目依赖jar包，包括各个模块jar和第三方jar
├── LICENSE       # LICENSE文件
├── licenses      # 运行时license
├── NOTICE        # NOTICE文件
├── script        # 集群启动、停止和服务监控启停脚本
└── sql           # 项目依赖sql文件

# 授权解压目录
sudo chown -R dolphinscheduler:dolphinscheduler dolphinscheduler-backend
# 授权安装目录
sudo chown -R dolphinscheduler:dolphinscheduler /opt/app/dolphinscheduler
</code></pre>
<h3 id="jdk软连接">jdk软连接</h3>
<pre><code class="language-sh">echo $JAVA_HOME    # 没有软连接后面在启动脚本的时候会报错：nohup /bin/java不存在
sudo ln -s /usr/java/jdk1.8.0_111/bin/java /usr/bin/java
原先软连接关联的是openjdk的需要删掉
</code></pre>
<h3 id="数据库初始化">数据库初始化</h3>
<ul>
<li>创建数据库</li>
</ul>
<pre><code class="language-mysql">mysql -uroot -p
-- 创建数据库
CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
-- 创建用户及授权（可能需要修改数据库密码等级）
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'dolphinscheduler'@'%' IDENTIFIED BY 'dolphinscheduler';
GRANT ALL PRIVILEGES ON dolphinscheduler.* TO 'dolphinscheduler'@'localhost' IDENTIFIED BY 'dolphinscheduler';
flush privileges;
</code></pre>
<ul>
<li>修改配置</li>
</ul>
<pre><code>vi conf/application-dao.properties
# 需要注释掉postgresql的信息
# postgre
#spring.datasource.driver-class-name=org.postgresql.Driver
#spring.datasource.url=jdbc:postgresql://localhost:5432/dolphinscheduler
# mysql
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://master:3306/dolphinscheduler?useUnicode=true&amp;characterEncoding=UTF-8     #需要修改ip，本机localhost即可
spring.datasource.username=dolphinscheduler
spring.datasource.password=dolphinscheduler
</code></pre>
<ul>
<li>执行脚本初始化数据表</li>
</ul>
<pre><code>sh script/create-dolphinscheduler.sh
</code></pre>
<p><strong>尖叫提示：执行脚本前需要下载mysql-java驱动程序包（需要选择对应mysql版本的驱动，不是bin），https://downloads.mysql.com/archives/c-j/</strong><br>
<strong>尖叫提示：如果执行上述脚本报 ”/bin/java: No such file or directory“ 错误，请在/etc/profile下配置 JAVA_HOME 及 PATH 变量</strong></p>
<h3 id="修改环境变量">修改环境变量</h3>
<pre><code class="language-sh">vi conf/env/.dolphinscheduler_env.sh    # 这是一个隐藏文件
# JAVA_HOME 和 PATH 是必须要配置的，其他没有用到的可以忽略或者注释掉
#export HADOOP_HOME=/opt/soft/hadoop
#export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop
#export SPARK_HOME1=/opt/soft/spark1
#export SPARK_HOME2=/opt/soft/spark2
#export PYTHON_HOME=/opt/soft/python
export JAVA_HOME=/usr/java/jdk1.8.0_111
#export HIVE_HOME=/opt/soft/hive
#export FLINK_HOME=/opt/soft/flink
export PATH=$HADOOP_HOME/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$PATH
</code></pre>
<h3 id="安装python的zookeeper工具kazoo每台都要安装">安装python的zookeeper工具kazoo（每台都要安装）</h3>
<pre><code>#安装pip
sudo yum -y install python-pip;  #ubuntu请使用 sudo apt-get install python-pip
sudo pip install kazoo;

# 注意：如果yum没找到python-pip，也可以通过下面方式安装
sudo curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python get-pip.py  # 如果是python3，使用sudo python3 get-pip.py
#然后
sudo pip install kazoo;
</code></pre>
<h3 id="修改一键部署脚本">修改一键部署脚本</h3>
<pre><code>vi install.sh
# for example postgresql or mysql ...
dbtype=&quot;mysql&quot;

# db config
# db address and port
dbhost=&quot;master:3306&quot;

# db name
dbname=&quot;dolphinscheduler&quot;

# db username
username=&quot;dolphinscheduler&quot;

# db passwprd
# Note: if there are special characters, please use the \ transfer character to transfer
passowrd=&quot;dolphinscheduler&quot;

# conf/config/install_config.conf config
# Note: the installation path is not the same as the current path (pwd)
# 将应用安装到哪个目录下
installPath=&quot;/opt/app/dolphinscheduler&quot;

# deployment user
# Note: the deployment user needs to have sudo privileges and permissions to operate hdfs. If hdfs is enabled, the root directory needs to be created by itself
# 使用哪个用户部署
deployUser=&quot;dolphinscheduler&quot;

# zk cluster,集群方式以逗号分隔
zkQuorum=&quot;master:2181,slave1:2181,slave2:2181&quot;

# install hosts
# Note: install the scheduled hostname list. If it is pseudo-distributed, just write a pseudo-distributed hostname
# 在哪些机器上部署
ips=&quot;master,slave1,slave2&quot;

# conf/config/run_config.conf config
# run master machine
# Note: list of hosts hostname for deploying master
masters=&quot;master,slave1&quot;

# run worker machine
# note: list of machine hostnames for deploying workers
workers=&quot;master,slave1,slave2&quot;

# run alert machine
# note: list of machine hostnames for deploying alert server
alertServer=&quot;master&quot;

# run api machine
# note: list of machine hostnames for deploying api server
apiServers=&quot;master&quot;

# 邮件服务
# alert config
# mail protocol
mailProtocol=&quot;SMTP&quot;

# mail server host
mailServerHost=&quot;hwSMTP.qiye.163.com&quot;

# mail server port
mailServerPort=&quot;994&quot;

# sender
mailSender=&quot;dtservice@bwton.com&quot;

# user
mailUser=&quot;dtservice@bwton.com&quot;

# sender password
mailPassword=&quot;BSngfWCyH7N8C5ZT&quot;

# TLS mail protocol support
starttlsEnable=&quot;false&quot;

sslTrust=&quot;hwSMTP.qiye.163.com&quot;

# SSL mail protocol support
# note: The SSL protocol is enabled by default.
# only one of TLS and SSL can be in the true state.
sslEnable=&quot;true&quot;

# download excel path
xlsFilePath=&quot;/tmp/xls&quot;

# 业务用到的比如sql等资源文件上传到哪里，可以设置：HDFS,S3,NONE，单机如果想使用本地文件系统，请配置为HDFS，因为HDFS支持本地文件系统；如果不需要资源上传功能请选择NONE。强调一点：使用本地文件系统不需要部署hadoop
resUploadStartupType=&quot;HDFS&quot;

# 这里以保存到本地文件系统为例
#注：但是如果你想上传到HDFS的话，NameNode启用了HA，则需要将core-site.xml和hdfs-site.xml放到conf目录下，本例即是放到/opt/dolphinscheduler/conf下面，并配置namenode cluster名称；如果NameNode不是HA,则修改为具体的ip或者主机名即可
defaultFS=&quot;hdfs://hadoopcluster/dolphinscheduler&quot;    #hdfs://{具体的ip/主机名}:8020

# 如果ResourceManager是HA，则配置为ResourceManager节点的主备ip或者hostname,比如&quot;192.168.xx.xx,192.168.xx.xx&quot;，否则如果是单ResourceManager或者根本没用到yarn,请配置yarnHaIps=&quot;&quot;即可，我这里没用到yarn，配置为&quot;&quot;
yarnHaIps=&quot;&quot;

# 如果是单ResourceManager，则配置为ResourceManager节点ip或主机名，否则保持默认值即可。我这里没用到yarn，保持默认
singleYarnIp=&quot;&quot;

# 由于hdfs支持本地文件系统，需要确保本地文件夹存在且有读写权限
hdfsPath=&quot;/data/dolphinscheduler&quot;
</code></pre>
<h3 id="执行一键部署脚本">执行一键部署脚本</h3>
<pre><code>su dolphinscheduler

sh install.sh
</code></pre>
<h3 id="查看进程是否启动">查看进程是否启动</h3>
<pre><code>jps

master
MasterServer         ----- master服务
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务
ApiApplicationServer ----- api服务
AlertServer          ----- alert服务

slave1
MasterServer         ----- master服务
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务

slave2
WorkerServer         ----- worker服务
LoggerServer         ----- logger服务
</code></pre>
<h3 id="解压">解压</h3>
<pre><code>tar -zxvf apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin.tar.gz -C /opt/soft/dolphinscheduler;
mv apache-dolphinscheduler-incubating-1.2.0-dolphinscheduler-front-bin dolphinscheduler-ui
</code></pre>
<h2 id="部署前端">部署前端</h2>
<h3 id="部署">部署</h3>
<h4 id="自动化部署">自动化部署</h4>
<ul>
<li>执行自动化部署脚本</li>
</ul>
<pre><code>cd dolphinscheduler-ui;
sh ./install-dolphinscheduler-ui.sh;
执行后，会在运行中请键入前端端口，默认端口是8888，如果选择默认，键入回车，或者键入其他端口
然后会让键入跟前端ui交互的api-server的ip
接着是让键入跟前端ui交互的api-server的port
接着是操作系统选择
等待部署完成
</code></pre>
<ul>
<li>修改nginx配置</li>
</ul>
<pre><code>vi /etc/nginx/nginx.conf
# add param 在http方法体内添加即可
client_max_body_size 1024m;
systemctl restart nginx
</code></pre>
<h4 id="手动部署">手动部署</h4>
<ul>
<li>安装nginx，官网下载: http://nginx.org/en/download.html 或者 yum install nginx -y</li>
<li>修改nginx配置文件</li>
</ul>
<pre><code>vi /etc/nginx/nginx.conf
server {
  listen       8888;# 访问端口(自行修改)
  server_name  localhost;
  #charset koi8-r;
  #access_log  /var/log/nginx/host.access.log  main;
  location / {
      root   /opt/app/dolphinscheduler-ui/dist;      # 前端解压的dist目录地址(自行修改)
      index  index.html index.html;
  }
  location /dolphinscheduler {
      proxy_pass http://localhost:12345;    # api服务地址(自行修改)
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header x_real_ipP $remote_addr;
      proxy_set_header remote_addr $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_http_version 1.1;
      proxy_connect_timeout 4s;
      proxy_read_timeout 30s;
      proxy_send_timeout 12s;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection &quot;upgrade&quot;;
  }
  #error_page  404              /404.html;
  # redirect server error pages to the static page /50x.html
  #
  error_page   500 502 503 504  /50x.html;
  location = /50x.html {
      root   /usr/share/nginx/html;
  }
}
</code></pre>
<h3 id="初始账号密码">初始账号密码</h3>
<p>地址：192.168.xx.xx:8888 用户名密码：admin/dolphinscheduler123</p>
<h2 id="指令">指令</h2>
<pre><code>启动：
    启动所有进程：sh bin/start-all.sh
    启动master-server：sh bin/dolphinscheduler-daemon.sh start master-server
    启动worker-server：sh bin/dolphinscheduler-daemon.sh start worker-server
    启动logger-server：sh bin/dolphinscheduler-daemon.sh start logger-server
    启动alert-server：sh bin/dolphinscheduler-daemon.sh start alert-server
    启动api-server：sh bin/dolphinscheduler-daemon.sh start api-server

停止：
    停止所有进程：sh bin/stop-all.sh
    停止master-server：sh bin/dolphinscheduler-daemon.sh stop master-server
    停止worker-server：sh bin/dolphinscheduler-daemon.sh stop worker-server
    停止logger-server：sh bin/dolphinscheduler-daemon.sh stop logger-server
    停止alert-server：sh bin/dolphinscheduler-daemon.sh stop alert-server
    停止api-server：sh bin/dolphinscheduler-daemon.sh stop api-server
</code></pre>
<h1 id="dolphinscheduler使用与测试文档">dolphinscheduler使用与测试文档</h1>
<h2 id="安全中心security">安全中心（Security）</h2>
<h3 id="队列管理queue-manage">队列管理（Queue manage）</h3>
<blockquote>
<p>队列是在执行 spark、mapreduce 等程序，需要用到“队列”参数时使用的（创建后不可删除）。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 队列管理 -&gt; 创建队列
------------------------------------------------------
名称：quene_test
队列值：quene_test
------------------------------------------------------
提交
</code></pre>
<h3 id="租户管理tenant-manage">租户管理（Tenant Manage）</h3>
<blockquote>
<p>租户对应的是 Linux 的用户，用于 worker 提交作业所使用的用户。<br>
如果 Linux 没有这个用户，worker 会在执行脚本的时候创建这个用户。<br>
租户编码：租户编码是 Linux 上的用户，唯一，不能重复。<br>
新建的租户会在 HDFS 上 $hdfsPath(&quot;/dolphinscheduler&quot;） 目录下创建租户目录，租户目录下为该租户上传的文件和 UDF 函数<br>
租户名称：租户编码的别名</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 租户管理 -&gt; 创建租户
------------------------------------------------------
租户编码：test
租户名称：test
队列值：default
------------------------------------------------------
提交

使用到HDFS需要为该用户在 HDFS 上创建用户目录
sudo -u hdfs hadoop fs -mkdir /user/developer
sudo -u hdfs hadoop fs -chown developer:developer /user/developer
</code></pre>
<h3 id="用户管理user-manage">用户管理（User Manage）</h3>
<blockquote>
<p>用户分为管理员用户和普通用户。<br>
授予权限包括：项目权限，资源权限，数据源权限，UDF函数权限。<br>
管理员可以对普通用户进行非其创建的项目、资源、数据源和UDF函数进行授权。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; 用户管理 -&gt; 创建用户
------------------------------------------------------
用户名称：test
密码：test123
租户：test
队列：default
邮箱：liuhao@bwton.com
手机号：
-----------------------------------------------------+-
提交
</code></pre>
<p><strong>实际生产环境中，可将 项目、用户、租户 相关联，即为某个大的项目创建一个用户及对应的租户。若需要删除用户，则应首先将项目内的任务删除，然后删除项目，再删除用户及关联的租户，否则会出现任务无法运行，项目不可见等情况（1.2 版本）<br>
如果该 用户切换租户，则该 用户在当前租户下创建的所有资源 将 复制 到新的租户下（对于 HDFS 平台来说，则是将当前租户目录下该用户创建的所有资源复制到新租户的目录下，不复制被赋权的文件，且被赋权的文件仍有权限）。需要注意的是，此后进行文件删除操作时，旧租户下的对应的文件并不会被删除。</strong></p>
<h3 id="告警组管理warning-group-manage">告警组管理（Warning group manage）</h3>
<blockquote>
<p>告警组是在启动时设置的参数，在流程结束以后会将流程的状态和其他信息以邮件形式发送给告警组。</p>
</blockquote>
<h3 id="worker分组管理worker-group-manage">Worker分组管理（Worker group manage）</h3>
<blockquote>
<p>worker 分组，提供了一种让任务在指定的 worker 上运行的机制。<br>
管理员创建 worker 分组，在任务节点和运行参数中设置中可以指定该任务运行的 worker 分组。<br>
如果指定的分组被删除或者没有指定分组，则该任务会在任意一个 worker 上运行。worker 分组内多个 ip 地址（不能写别名），以英文逗号分隔。</p>
</blockquote>
<p>例：</p>
<pre><code>安全中心 -&gt; Worker分组管理 -&gt; 创建Worker分组
------------------------------------------------------
组名称：worker_group1
IP：10.10.0.87
------------------------------------------------------
提交
</code></pre>
<h3 id="令牌管理token-manage">令牌管理（Token manage）</h3>
<blockquote>
<p>由于后端接口有登录检查，令牌管理，提供了一种可以通过调用接口的方式对系统进行各种操作。</p>
</blockquote>
<h2 id="监控中心monitor">监控中心（Monitor）</h2>
<p>略</p>
<h2 id="数据源中心datasource">数据源中心（Datasource）</h2>
<pre><code>数据源中心 -&gt; 创建数据源 -&gt; MYSQL
------------------------------------------------------
数据源名称：10.10.0.87
描述：
IP主机名：10.10.0.87
端口：3306
用户名：root
密码：Bwton@2018
数据库名：test
jdbc连接参数：{&quot;useSSL&quot;:&quot;false&quot;,&quot;useUnicode&quot;:&quot;true&quot;,&quot;characterEncoding&quot;:&quot;UTF-8&quot;,&quot;allowMultiQueries&quot;:&quot;true&quot;}
------------------------------------------------------
测试链接 -&gt; 编辑
</code></pre>
<p>其他数据源：略</p>
<h2 id="资源中心resources">资源中心（Resources）</h2>
<blockquote>
<p>资源中心所有文件对应的 Mysql 表为：t_ds_resources<br>
UDF 对应的 Mysql 表为：t_ds_udfs<br>
资源中心的文件上传、删除操作使用的用户均为 install.sh 中指定的 $hdfsRootUser</p>
</blockquote>
<p>由于没有使用HDFS，略</p>
<h2 id="项目管理project">项目管理（Project）</h2>
<h3 id="创建项目">创建项目</h3>
<blockquote>
<p>项目名称 不可重复。即使为不同用户，创建项目时若 项目名称 已存在。会提示 “project Test already exists”。<br>
若要删除项目，需要确认项目中所有 工作流定义 都已下线并删除，才能进行删除操作。<br>
实际生产环境中，建议使用 管理员账户 创建项目，并对开发人员赋权。</p>
</blockquote>
<p>例：</p>
<pre><code>项目管理 -&gt; 创建项目
------------------------------------------------------
项目名称：测试项目
描述：
------------------------------------------------------
提交
</code></pre>
<h3 id="项目首页">项目首页</h3>
<pre><code>项目名称 -&gt; 项目首页
------------------------------------------------------
任务状态统计：是指在指定时间范围内，统计 任务实例 中的待运行、失败、运行中、完成、成功的个数
流程状态统计：是指在指定时间范围内，统计 工作流实例 中的待运行、失败、运行中、完成、成功的个数
流程定义统计：是统计当前用户有权限的项目的 工作流定义 总数
</code></pre>
<p><strong>工作流定义的工作流每运行一次，产生一个工作流实例，一个工作流实例包含一到多个任务实例。同一任务实例仅被统计一次，按最近时间状态进行统计。</strong></p>
<h3 id="工作流定义">工作流定义</h3>
<h4 id="创建工作流定义">创建工作流定义</h4>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
Step 1：拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
------------------------------------------------------
节点名称：task01
描述：This is a test task.
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
脚本：
    #!/bin/sh
    echo &quot;HELLO WORLD.&quot;
资源：
自定义参数：
------------------------------------------------------
    确认添加

Step 2：拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
------------------------------------------------------
节点名称：task02
描述：This is another test task.
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
脚本：
    #!/bin/sh
    echo &quot;HELLO DOLPHIN SCHEDULER.&quot;
资源：
自定义参数：
-&gt; 确认添加
------------------------------------------------------
Step 3：“选择线条连接”，连接任务1、2，tesk01、task02 会串行执行。
Step 4：保存
------------------------------------------------------
设置DAG图名称：Test_shell
选择租户：test
------------------------------------------------------
-&gt; 添加
</code></pre>
<p>更多任务类型详见：</p>
<h4 id="工作流定义操作功能">工作流定义操作功能</h4>
<p>工作流定义列表的操作功能如下：</p>
<ul>
<li>编辑： 只能编辑&quot;下线&quot;的工作流定义。工作流DAG编辑同创建工作流定义。</li>
<li>上线： 工作流状态为&quot;下线&quot;时，上线工作流，只有&quot;上线&quot;状态的工作流能运行，但不能编辑。</li>
<li>下线： 工作流状态为&quot;上线&quot;时，下线工作流，下线状态的工作流可以编辑，但不能运行。</li>
<li>运行： 只有上线的工作流能运行。运行操作步骤见 5.5.3.3 运行工作流</li>
<li>定时： 只有上线的工作流能设置定时，系统自动定时调度工作流运行。创建定时后的状态为&quot;下线&quot;，需在定时管理页面上线定时才生效。定时操作步骤见 5.5.3.4 工作流定时。</li>
<li>定时管理： 定时管理页面可编辑、上线/下线、删除定时。</li>
<li>删除： 删除工作流定义。</li>
<li>下载： 下载工作流定义到本地</li>
<li>树形图： 以树形结构展示任务节点的类型及任务状态</li>
</ul>
<h4 id="运行工作流">运行工作流</h4>
<p>工作流运行参数说明：</p>
<ul>
<li>失败策略：当某一个任务节点执行失败时，其他并行的任务节点需要执行的策略。”继续“表示：某一任务失败后，其他任务节点正常执行；”结束“表示：终止所有正在执行的任务，并终止整个流程。</li>
<li>通知策略：当流程结束，根据流程状态发送流程执行信息通知邮件，包含任何状态都不发，成功发，失败发，成功或失败都发。</li>
<li>流程优先级：流程运行的优先级，分五个等级：最高（HIGHEST），高(HIGH),中（MEDIUM）,低（LOW），最低（LOWEST）。当master线程数不足时，级别高的流程在执行队列中会优先执行，相同优先级的流程按照先进先出的顺序执行。</li>
<li>worker分组：该流程只能在指定的worker机器组里执行。默认是Default，可以在任一worker上执行。</li>
<li>通知组：选择通知策略||超时报警||发生容错时，会发送流程信息或邮件到通知组里的所有成员。</li>
<li>收件人：选择通知策略||超时报警||发生容错时，会发送流程信息或告警邮件到收件人列表。</li>
<li>抄送人：选择通知策略||超时报警||发生容错时，会抄送流程信息或告警邮件到抄送人列表。</li>
<li>补数：包括串行补数、并行补数2种模式。串行补数：指定时间范围内，从开始日期至结束日期依次执行补数，只生成一条流程实例；并行补数：指定时间范围内，多天同时进行补数，生成N条流程实例。</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 选择工作流名称“Test_shell” -&gt; 上线 -&gt; 运行（参数均为默认，不做修改）
</code></pre>
<h4 id="工作流定时">工作流定时</h4>
<pre><code>选择指定工作流，点击“定时”，选择起止时间、定时等选择定时执行时间。

点击&quot;创建&quot;按钮，创建定时成功，此时定时状态为&quot;下线&quot;，定时需上线才生效。
定时上线：点击&quot;定时管理&quot;按钮，进入定时管理页面，点击&quot;上线&quot;按钮，定时状态变为&quot;上线&quot;，如下图所示，工作流定时生效。
</code></pre>
<p><strong>下线 工作流定义 后，定时任务业务也会同时下线，工作流定义 上线后，需要重新手动上线定时任务</strong></p>
<h4 id="导入工作流">导入工作流</h4>
<pre><code>点击项目管理-&gt;工作流-&gt;工作流定义，进入工作流定义页面，点击&quot;导入工作流&quot;按钮，导入本地工作流文件，工作流定义列表显示导入的工作流，状态为下线。
</code></pre>
<h4 id="工作流实例">工作流实例</h4>
<p>工作流实例操作功能：</p>
<ul>
<li>编辑：可以对已经终止的流程进行编辑，编辑后保存的时候，可以选择是否 更新到工作流定义</li>
<li>重跑：可以对已经终止的流程进行重新执行</li>
<li>恢复失败：针对失败的流程，可以执行恢复失败操作，从失败的节点开始执行</li>
<li>停止：对正在运行的流程进行停止操作，后台会先 kill worker 进程，再执行 kill -9 操作</li>
<li>暂停：可以对正在运行的流程进行暂停操作，系统状态变为等待执行，会等待正在执行的任务结束，暂停下一个要执行的任务</li>
<li>恢复暂停：可以对暂停的流程恢复，直接从暂停的节点开始运行</li>
<li>删除：删除工作流实例及工作流实例下的任务实例</li>
<li>甘特图：Gantt图纵轴是某个工作流实例下的任务实例的拓扑排序，横轴是任务实例的运行时间</li>
</ul>
<pre><code>查看工作流实例：
项目管理 -&gt; 工作流 -&gt; 工作流实例 -&gt; 点击工作流名称 -&gt; 进入DAG查看页面，查看任务执行状态

查看任务日志：
进入DAG查看页面 -&gt; 双击任务节点 -&gt; 查看日志

查看任务历史记录：
进入DAG查看页面 -&gt; 双击任务节点 -&gt; 查看历史

查看运行参数：
进入工作流DAG页面 -&gt; 点击左上角图标，查看工作流实例的启动参数、全局参数和局部参数
</code></pre>
<h4 id="任务实例">任务实例</h4>
<pre><code>任务实例 -&gt; 点击工作流实例名称 -&gt; 可跳转到工作流实例DAG图查看任务状态
任务实例 -&gt; 查看日志
</code></pre>
<h3 id="任务节点类型和参数设置">任务节点类型和参数设置</h3>
<h4 id="shell节点">Shell节点</h4>
<p>运行说明：shell 节点，在 worker 执行的时候，会生成一个临时 shell 脚本，使用租户同名的linux 用户执行这个脚本。<br>
参数说明：</p>
<ul>
<li>节点名称：一个工作流定义中的节点名称是唯一的</li>
<li>运行标志：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关</li>
<li>描述信息：描述该节点的功能</li>
<li>任务优先级：级别高的任务在执行队列中会优先执行，相同优先级的任务按照先进先出的顺序执行</li>
<li>Worker分组：指定任务运行的机器列表</li>
<li>失败重试次数：任务失败重新提交的次数，支持下拉和手填</li>
<li>失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填</li>
<li>超时告警：当任务执行时间超过超时时长可以告警并且超时失败</li>
<li>脚本：用户开发的SHELL程序</li>
<li>资源：是指脚本中需要调用的资源文件列表</li>
<li>自定义参数：是SHELL局部的用户自定义参数，会替换脚本中以${变量}的内容</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

拖拽“SHELL&quot;节点到画布，新增一个Shell任务。
节点名称：Test_shell_01
运行标志：正常
描述：
任务优先级：MEDIUM
Worker分组：Default
失败重试次数：0
失败重试间隔：1
超时告警：off
脚本：
    #!/bin/sh
    for i in {1..10};do echo $i;done
资源：
自定义参数：
-&gt; 确认添加

------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_shell
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="子流程节点">子流程节点</h4>
<p>运行说明：子流程节点，就是把外部的某个工作流定义当做一个任务节点去执行。<br>
参数说明：</p>
<ul>
<li>节点名称：一个工作流定义中的节点名称是唯一的</li>
<li>运行标志：标识这个节点是否能正常调度</li>
<li>描述信息：描述该节点的功能</li>
<li>超时告警：勾选超时告警、超时失败，当任务超过&quot;超时时长&quot;后，会发送告警邮件并且任务执行失败</li>
<li>子节点：是选择子流程的工作流定义，右上角进入该子节点可以跳转到所选子流程的工作流定义</li>
</ul>
<p>例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

Task 1：拖拽 SHELL 节点到画布，新增一个 Shell 任务
节点名称：Test_subprocess_01
... ...
脚本：
    #!/bin/sh
    for i in {1..10};do echo $i;done
-&gt; 确认添加
Task 2：拖拽 SUB_PROCESS 节点到画布，新增一个 SUB_PROCESS 任务
节点名称：Test_subprocess_02
... ...
子节点：Test_shell
-&gt; 确认添加

------------------------------------------------------

串联任务节点 Task1 和 Task2
------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_subprocess
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="存储过程节点">存储过程节点</h4>
<p>运行说明：根据选择的数据源，执行存储过程。<br>
参数说明：</p>
<ul>
<li>数据源：存储过程的数据源类型支持 MySQL、POSTGRESQL、CLICKHOUSE、ORACLE、SQLSERVER 等，选择对应的数据源</li>
<li>方法：是存储过程的方法名称</li>
<li>自定义参数：存储过程的自定义参数类型支持 IN、OUT 两种，数据类型支持 VARCHAR、INTEGER、LONG、FLOAT、DOUBLE、DATE、TIME、TIMESTAMP、BOOLEAN 九种数据类型</li>
</ul>
<h4 id="sql节点">SQL节点</h4>
<p>参数说明：</p>
<ul>
<li>数据源：选择对应的数据源</li>
<li>sql类型：支持查询和非查询两种，查询是 select 类型的查询，是有结果集返回的，可以指定邮件通知为 表格、附件 或 表格与附件 三种模板。非查询是没有结果集返回的，是针对 update、delete、insert 三种类型的操作</li>
<li>主题、收件人、抄送人：邮件相关配置</li>
<li>sql参数：输入参数格式为 key1=value1;key2=value2…</li>
<li>sql语句：SQL语句</li>
<li>UDF函数：对于HIVE类型的数据源，可以引用资源中心中创建的UDF函数,其他类型的数据源暂不支持UDF函数</li>
<li>自定义参数：SQL任务类型，而存储过程是自定义参数顺序的给方法设置值自定义参数类型和数据类型同存储过程任务类型一样。区别在于SQL任务类型自定义参数会替换sql语句中 ${变量}</li>
<li>前置sql：执行 “sql语句” 前的操作</li>
<li>后置sql：执行 “sql语句” 后的操作</li>
</ul>
<p>例，以mysql为例：</p>
<pre><code>项目管理 -&gt; 工作流 -&gt; 工作流定义 -&gt; 创建工作流
------------------------------------------------------

Task 1：拖拽 SQL 节点到画布，新增一个 SQL 任务
节点名称：Test_sql_mysql_01
... ...
数据源：MYSQL   10.10.0.87
sql类型：查询   表格：√ 附件：√
主题：Test MySQL
收件人：liuhao@bwton.com
sql语句：
    select * from test_table where score=${i};
自定义参数：
    i -&gt; IN -&gt; INTEGER -&gt; 97
前置sql:
    INSERT INTO test_table values(null, 'Dog',97)
后置sql：
-&gt; 确认添加
Task 2：拖拽 SQL 节点到画布，新增一个 SQL 任务
节点名称：Test_sql_mysql_02
... ...
数据源：MYSQL   10.10.0.87
sql类型：非查询
sql语句：
    create table test_table2 as select * from test_table;
自定义参数：
前置sql:
后置sql：
-&gt; 确认添加

------------------------------------------------------

串联任务节点 Test_sql_mysql_01、Test_sql_mysql_02
------------------------------------------------------

保存 -&gt;
设置DAG图名称：Test_sql_mysql
选择租户：Default
超时告警：off
设置全局：

------------------------------------------------------

添加 -&gt; 上线 -&gt; 运行
</code></pre>
<h4 id="依赖dependent节点">依赖(DEPENDENT)节点</h4>
<p>运行说明：依赖节点，就是依赖检查节点。比如A流程依赖昨天的B流程执行成功，依赖节点会去检查B流程在昨天是否有执行成功的实例。</p>
<h4 id="其他节点略">其他节点，略</h4>
<h2 id="参数">参数</h2>
<h3 id="系统参数">系统参数</h3>
<table>
<thead>
<tr>
<th>变量</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>${system.biz.date}</td>
<td>日常调度实例定时的定时时间前一天，格式为 yyyyMMdd，补数据时，该日期 +1</td>
</tr>
<tr>
<td>${system.biz.curdate}</td>
<td>日常调度实例定时的定时时间，格式为 yyyyMMdd，补数据时，该日期 +1</td>
</tr>
<tr>
<td>${system.datetime}</td>
<td>日常调度实例定时的定时时间，格式为 yyyyMMddHHmmss，补数据时，该日期 +1</td>
</tr>
</tbody>
</table>
<h3 id="自定义参数">自定义参数</h3>
<ul>
<li>支持代码中自定义变量名，声明方式：${变量名}。可以是引用 &quot;系统参数&quot; 或指定 &quot;常量&quot;。</li>
<li>我们定义这种基准变量为 [...] 格式的，[yyyyMMddHHmmss] 是可以任意分解组合的，比如：$[yyyyMMdd], $[HHmmss], $[yyyy-MM-dd] 等</li>
<li>也可以使用以下格式：</li>
</ul>
<pre><code>* 后 N 年：$[add_months(yyyyMMdd,12*N)]
* 前 N 年：$[add_months(yyyyMMdd,-12*N)]
* 后 N 月：$[add_months(yyyyMMdd,N)]
* 前 N 月：$[add_months(yyyyMMdd,-N)]
* 后 N 周：$[yyyyMMdd+7*N]
* 前 N 周：$[yyyyMMdd-7*N]
* 后 N 天：$[yyyyMMdd+N]
* 前 N 天：$[yyyyMMdd-N]
* 后 N 小时：$[HHmmss+N/24]
* 前 N 小时：$[HHmmss-N/24]
* 后 N 分钟：$[HHmmss+N/24/60]
* 前 N 分钟：$[HHmmss-N/24/60]
</code></pre>
<h2 id="官方使用文档">官方使用文档</h2>
<p><a href="https://dolphinscheduler.apache.org/zh-cn/docs/1.2.0/user_doc/quick-start.html">https://dolphinscheduler.apache.org/zh-cn/docs/1.2.0/user_doc/quick-start.html</a></p>
<h2 id="出现的问题">出现的问题</h2>
<h3 id="创建租户">创建租户</h3>
<ul>
<li>租户对应的是Linux的用户，用于worker提交作业所使用的用户。如果linux没有这个用户，worker会在执行脚本的时候创建这个用户。</li>
<li>租户编码：租户编码是Linux上的用户，唯一，不能重复</li>
<li>出现创建不了租户原因
<ol>
<li>ds的启动用户没有创建用户的权限</li>
<li>linux系统禁用了sudo，进入/etc/sudoers 将 Default requiretty注释掉</li>
</ol>
</li>
</ul>
<h3 id="创建用户-2">创建用户</h3>
<ul>
<li>权限划分，目的是为了更好的管理项目，资源，UDF，数据源等信息。</li>
<li>创建用户需要指定租户（要想admin用户有执行权限，需要给admin用户赋予租户）</li>
</ul>
<h3 id="调度未执行">调度未执行</h3>
<blockquote>
<p>定时任务上线成功，调度未执行，查看master没有打印错误日志</p>
</blockquote>
<ul>
<li>原因可能是quartz在启动时就报错了，导致quartz初始化没有成功。</li>
<li>修改master_logback.xml</li>
</ul>
<pre><code>&lt;root level=&quot;INFO&quot;&gt;
    &lt;appender-ref ref=&quot;MASTERLOGFILE&quot;/&gt;
    &lt;!-- 增加日志到控制台--&gt;
    &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;
&lt;/root&gt;
</code></pre>
<ul>
<li>查看master.out文件</li>
</ul>

                </div>
            </article>
        </div>

        

        

        

        

        <div class="site-footer gt-c-content-color-first">
    <div class="slogan gt-c-content-color-first">温故而知新</div>
    <div class="social-container">
        
            
        
            
        
            
        
            
        
            
        
            
        
    </div>
    <div class="footer-info">
        Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
    </div>
    <div>
        Theme by <a href="https://imhanjie.com/" target="_blank">imhanjie</a>, Powered by <a
                href="https://github.com/getgridea/gridea" target="_blank">Gridea | <a href="https://lhlh1994.github.io/atom.xml" target="_blank">RSS</a></a>
    </div>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

    </div>
</div>
</body>
</html>
